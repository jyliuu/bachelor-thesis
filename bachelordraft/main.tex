\documentclass[11pt, a4paper]{article}
\usepackage[margin=3cm]{geometry} 
\usepackage[english, science, hyperref]{ku-frontpage}
\usepackage[utf8]{inputenc}
\usepackage{amsmath,amssymb,amsthm,bm}
\usepackage{mdframed}
\usepackage{float}
\usepackage{mathtools}
\usepackage[
    backend=biber,
    style=alphabetic
]{biblatex}
\bibliography{references.bib}

\setlength\parindent{0pt}
\DeclareMathOperator*{\argmax}{arg\,max} 
\DeclareMathOperator*{\argmin}{arg\,min}
\newcommand{\indep}{\perp \!\!\! \perp}
\newcommand\norm[1]{\lVert#1\rVert}

\newtheorem{theorem}{Theorem}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{remark}{Remark}

\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\theoremstyle{remark}
\usepackage{mdframed}

\mdfdefinestyle{examplestyle}{%
    linewidth=1pt,
    innerleftmargin=10pt,
    innerrightmargin=10pt,
    skipabove=10pt, % add vertical space above
    skipbelow=10pt, % add vertical space below
    frametitlefont=\bfseries,
    nobreak=true
}
\newtheorem{example}{Example}
\surroundwithmdframed[style=examplestyle]{example}


\setlength\arraycolsep{2 pt}
\setcounter{tocdepth}{2}
\setcounter{secnumdepth}{2}

\newcommand{\q}{q}
\newcommand{\ml}{k}
\newcommand{\btheta}{\theta}
\newcommand{\lib}{\Theta}
\newcommand{\empmod}{\mathcal{P}_{\text{emp}}}
\DeclareMathOperator{\expit}{expit}

\assignment{A Bachelor of Science thesis}
\author{Jinyang Liu}


\title{Super Learners}
\subtitle{and their oracle properties}
\date{Submitted: \today}
\advisor{Supervised by Prof. Thomas Gerds\\ Co-supervised by Prof. Niels Richard Hansen \\Department of Mathematical Sciences \\University of Copenhagen, Denmark}
% \frontpageimage{example.png}

\begin{document}
\begingroup
    \fontencoding{T1}\fontfamily{lmr}\selectfont
    \maketitle
    \tableofcontents
    \newpage
\endgroup


\section{Introduction}
In the context of regression, a natural goal is to estimate a regression function $ \theta $ such that the $ L^2 $-risk or mean squared error $ E(Y - \theta(X))^2 $ for $ n $ observations $ O = (Y, X) $ is minimized. It turns out that the conditional mean $ x \mapsto E(Y \mid X = x) $ minimizes the squared error, but the conditional mean can only be identified if we know the underlying data-generating process $ P \in \mathcal{P} $ for which $ O \sim P $. We typically make certain assumptions about the statistical model, $\mathcal{P}$, in which we believe $P$ resides. For instance, we might assume that $\mathcal{P}$ is a curved exponential family. In doing so we are able to identify through maximum likelihood techniques, the parameters of the distribution $ P $ and achieve an asymptotic convergence rate of $ O\left(\frac{1}{\sqrt{n}}\right) $. \cite{lauritzen2022statistics}[ch. 5]

However, if we are dealing with highly complex data, there is a risk of misspecifying the model by identifying it as an exponential family. Our assumptions may be biased. In such situations, it is more appropriate to utilize non-parametric and data-driven regression methods, such as tree-based algorithms like XGBoost or random forests, to estimate the conditional mean. On the other hand, the assumptions of these data-driven methods regarding $ \mathcal{P} $ are not explicit. We can nevertheless incorporate these methods as a part of our repertoire, but it is important that we can compare and choose the best method that most effectively accomplishes our goal. 

The ``super learner'' is the answer to how we can effectively select the `best' learner -- regression estimate -- among the learners that we have in our library of learners. We will demonstrate that the cross-validation selector, which evaluates learners based on their cross-validated (empirical) risk and chooses the one with the lowest risk, is asymptotically equivalent to the oracle selector. The oracle selector identifies the learner with the lowest true risk â€“ the theoretical risk achieved by the true distribution.

The discrete super learner is then obtained by applying the cross-validation selector to a library of learners. The asymptotic result shows that the risk of the super learner will be the same as the learner selected by the oracle selector when the number of observations goes to $ \infty $. The discrete super learner is not a fixed learner from our library, but rather depends on the available data. It represents the learner chosen by the cross-validation selector, which can vary depending on the amount of data at hand.

We first present the general theory and our goal, which is to estimate the conditional mean $ E(Y \mid X = x) $ for a observation  $ (Y, X) $ being a outcome-covariate pair. More specifically, we focus on the case where we regress on a binary outcome $ Y \in \{0,1\} $. The conditional expectation of $ Y $ given $ X $ exactly becomes the conditional probability $ P(Y = 1 \mid X = x) $. The choice to focus on binary regression stems from its significance in various fields. For instance, in biomedicine, researchers might want to predict patient mortality upon administering a specific drug. The survival indicator for the patient is a binary outcome, and the regression $ P(Y = 1 \mid X = x) $ could represent the probability of the patient's survival. 

\section{Background}

Our setup and notation is similar to \cite{vaart06} and \cite{laan03}:
Let a statistical model $ \mathcal{P} $ be given on the measurable space $ (\mathcal{O}, \mathcal{A}) $ where $ \mathcal{O} = \{0,1\} \times \mathcal{X} $ is our sample space for some $ \mathcal{X} \subseteq \mathbb{R}^{d} $. 
%Let $ O_1 = (Y_1 , X_1), \ldots, O_n = (Y_n, X_n) \in \mathcal{O} = \{0,1\} \times \mathcal{X} $ be $ n $-i.i.d. observations distributed according to $ P \in \mathcal{P} $ on some measurable space $ (\mathcal{O}, \mathcal{A}) $.
We will consider the parameter set $ \Theta = \{\btheta \mid \btheta : \mathcal{X} \to [0,1]\} $, which represents the set of \textbf{regression functions} that map from our covariates to the probability interval. We define the quadratic loss and the corresponding risk that we wish to minimize 
\begin{definition}[Quadratic loss]
    The quadratic loss or $ L^2 $-loss, $ L : \mathcal{O} \times \Theta \to [0, \infty) $, for an observation $ o \in \mathcal{O} $ and a regression function $ \btheta \in \Theta $ is defined as 
\begin{align*}
    L(o, \btheta) = L((y,x), \btheta) = (y - \btheta(x))^2.
\end{align*}
\end{definition}
A natural aim would be to find the optimal parameter value $\btheta^* \in \Theta$ that minimizes the expected $L^2$-loss, or conditional risk \cite{laan03}[p. 2] $R: \btheta \to \mathbb{R}$ given by 
\begin{equation} \label{l2risk}
    R(\btheta, P) := \int L(o, \btheta)  dP(o).
\end{equation}
Theorem \ref{minrisk} shows that the minimum risk is achieved by the conditional probability $ x \mapsto P(Y = 1\mid X = x) $. 
\begin{theorem} \label{minrisk}
    Let $ (\mathcal{O} , \mathcal{A}, P) $ be a probability space for some probability measure $ P \in \mathcal{P} $. Let $ \Theta $ be the set of regression functions of the form $ \btheta : \mathcal{X} \to [0,1] $. Let the loss function be the $ L^2 $-loss $ L(o, \btheta) = (y - \btheta(x))^2 $, then for the optimum $ \btheta^* $ defined as 
    \begin{align*}
        \btheta^* := \argmin_{\btheta \in \Theta} R(\btheta, P)= \argmin_{\btheta \in \Theta} \int L(o, \btheta)  dP(o),
    \end{align*}
    it holds for an observation $ O = (Y, X) \sim P $ that
    \begin{align*}
        \btheta^{*}(x) = E(Y \mid X = x) 
    \end{align*}
\end{theorem}
\begin{proof}
    See \cite{gyorfi2002distribution}[ch. 1]
\end{proof}
It follows immediately that if $ Y $ is binary, then $ E(Y \mid X = x) = P(Y = 1 \mid X = x) $. 


As we do not have access to the data-generating process $ P $, our goal is to estimate $ \btheta^{*} $, this means to \textbf{learn} the true regression function from our data. 
We will therefore introduce the terminology \textbf{learning algorithm} and \textbf{learner} in the context of learning from our data.  

\subsection{Learning algorithms and learners}
Moving forward, we will denote $ O_1 , \dots , O_n \in \mathcal{O} $ as our \textbf{observations}, and $ D_n = (O_1 , \dots , O_n) $ as our \textbf{data}. 
\begin{definition}[Learning algorithm $ \btheta $]
    An learning algorithm is a measurable map $ \btheta : \mathcal{O}^{n} \to \Theta $ for $ n \in \mathbb{N} $. 
\end{definition}

We use the notation $ \btheta $ for the learning algorithm, which coincides with the notation for a regression function. Indeed, it makes sense in this context since we would like to emphasize that the outcome of applying a learning algorithm to our data, $\btheta(D_n) $, is a regression function. We refer to that outcome as a \textbf{learner}. We will furthermore assume that the learning algorithm is well defined for each $ n \in \mathbb{N} $, and that permuting the observations have no effect on the outcome, i.e., the algorithm is symmetric in the observations.  

However, note that formally $ \btheta(D_n) $ is a stochastic variable since $ D_n $ is stochastic. In practice, we would have observed $ O_3 = o_1, \dots, O_n = o_n $, and subsequently, we can apply our learning algorithm on $ D_n = (o_1 , \dots , o_n) $, which is a particular instance of a dataset. We will refer the quantity, $ \btheta(D_n) $, as a \textbf{fitted learner}. 
\begin{example}[Parametric and nonparametric learning algorithms]
    An example of a parametric learner is logistic regression. In logistic regression we assume that the conditional probability, $ P(Y = 1 \mid X = x) $, can be expressed as $ \btheta(x) = \expit( \beta x) $ for some $ \beta \in \mathbb{R}^{d} $. The parameter $ \beta $ can be estimated via maximum likelihood.   

Nonparametric learning algorithms such as gradient boosting, for example XGBoost, can also be used to estimate the regression function. The gradient boosting algorithm, XGBoost, has a number of hyperparameters that can be tuned. These include, number of boosted trees, depth of each tree, learning rates, etc., but most importantly the internal loss objective which could for example be log-loss or mean squared error. XGBoost aims to iteratively refine the fitted learner by approximating the data $x \mapsto f_m(x)$ at each step $m$. It does so by introducing a new tree $h_m(x)$, which is trained on the error of $ f_m(x)$, such that $f_{m + 1}(x) = f_m(x) + h_m(x)$. The internal loss of the updated learner, $f_{m + 1}$, evaluated on the training data, is lower than that of the previous learner due to the inclusion of the new tree \cite{chen2016xgboost}.

The parameters of the resulting fit are not directly interpretable. Despite this, XGBoost has demonstrated its ability to model very complex datasets \cite{chen2016xgboost}.

\end{example}
There is a one-to-one correspondence between our data $ D_n $ and the empirical measures over $ n $ observations on $ (\mathcal{O} , \mathcal{A}) $ defined as
\begin{align*}
    P_n(A) = \frac{1}{n} \sum_{i = 1}^{n} \delta_{O_i}(A)\qquad \text{ for } A \in \mathcal{A},
\end{align*}
given that the observations are independent and identically distributed, so permuting the order of the observations does not matter. We can, therefore, write $ \btheta(P_n)$ as an alternative representation of the learner $\btheta(D_n)$, by adjusting the notation slightly without introducing ambiguity. The motivation for using this notation will become clearer in the subsequent section, where we introduce the discrete super learner.


%\begin{example}[Regression functions $ \btheta $] \label{ex:regfunc}
%    Let $ O_1 = (Y_1 , X_1) ,\ldots, O_n = (Y_n , X_n) \in  \mathcal{O} = \mathbb{R} \times \mathcal{X} $ be i.i.d. observations distributed according to some $ P \in \mathcal{P} $ such that they satisfy the model 
%    \begin{align*}
%        Y_1 = \btheta_0(X_1) + \varepsilon,
%    \end{align*}
%    for an unobservable stochastic error term $ \varepsilon $. The goal is to estimate an unknown \textbf{regression function} $ \btheta_0 \in \Theta $ where $ \btheta = \{\btheta \mid \btheta : \mathcal{X} \to \mathbb{R}\}$, is the set of possible regression functions each having $ \mathcal{X} $ as their domain. \cite{vaart06}
%\end{example}
%\begin{example}[Parametric statistical model] \label{ex:parametricfam}
%    In the case where we have $ n $-i.i.d. observations distributed according to some data-generating process $ P \in \mathcal{P} $, we have that each $ O_i = (Y_i , X_i) $, and $ X_i $ is a stochastic variable. The distribution $ P $ factorizes essentially into two parts, the conditional distribution of $ Y $ given $ X $ and the background distribution of $ X $, so $ P = P_{Y \mid X = x} \cdot P_X $. In this setup we are doing estimation with random design \cite{gyorfi2002distribution}.  
%
%We can formalize the setup as follows: $ O = (Y, X) \sim P $, if $ Y $ is $ \mathcal{B}(\mathbb{R})-\mathcal{B}(\mathbb{R}) $ measurable and $ X $ is $ \mathcal{F} - \mathcal{B}(\mathbb{R})  $ measurable for some sigma-algebra $ \mathcal{F} $ on $ \mathcal{X} $, then a \textbf{generalized regression model} could be considered as parametrized family of distributions, $ \mathcal{P} = \{P_{\btheta} \mid \btheta \in \Theta\} $, given that $ \btheta $ is finite-dimensional.
%
%    We can parametrize the conditional probability distributions for $ Y_1 $ given $ X_1 = x $ as $ \mathcal{Q} = \{Q_{\btheta(x)} \mid \btheta \in \Theta \} $ such that $ Q_{\btheta(x)} $ is a valid probability distribution on $ \mathcal{B}(\mathbb{R}) $ for each $ x \in X $ and $ \btheta \in \Theta $. For a given $ P_{\btheta} \in \mathcal{P} $ there will exist a $ Q_{\btheta} \in \mathcal{Q} $ such that  
%    \begin{align*}
%        P_{\btheta}(Y \in A \mid X = x) = Q_{ \btheta(x)}(A) \qquad \text{for all } A \in \mathcal{B}(\mathbb{R}).
%    \end{align*}
%    If we assume that $ X_1 $ is distributed according to some $ H_0 $ on $ \mathcal{X} $, then the distribution $ P_{\btheta} $ over our observations (the joint over $ Y $ and $ X $) will be
%    \begin{align*}
%        P_{\btheta }(X \in A, Y \in B ) = \int_{A} Q_{\btheta(x)}(B) d H_{0}(x) 
%    \end{align*}
%    for every $ A \in \mathcal{F} $ and $ B \in \mathcal{B}(\mathbb{R}) $. 
%\end{example}
%\begin{example}[Logistic regression model] \label{logregmod}
%    Let $ O_1 = (Y_1 , X_n) , \ldots, O_n = (Y_n , X_n) \in \mathcal{O} = \{0,1\} \times \mathcal{X} $ be i.i.d. observations from some distribution $ P_{\btheta_0} \in \mathcal{P} $, where $ Y_i $ is binary and $ \mathcal{X} \subseteq \mathbb{R}^{k} $. We would like to estimate the parameter function $ \btheta_{0} \in \Theta $
%\begin{align*}
%    \btheta_0(x) = E(Y_1 \mid X_1 = x) = P_{\btheta_0}(Y_1 = 1 \mid X_1 = x),
%\end{align*}
%In logistic regression we assume that $ \btheta = \{x \mapsto \expit(\beta x) \mid \beta \in \mathbb{R}^{k}\} $, so $ \btheta_0(x) = \expit(\beta_0 x) $, then the goal becomes to estimate the $ k $-dimensional parameter $ \beta_0 $, in this case the $ \mathbb{R}^{k} $ parameter $ \beta_0  $ completely determines $ \btheta_0 $, so $ \btheta $ is also $ k $-dimensional. % I am not sure if the last is true
%
%The conditional distributions of $ Y_1 $ given $ X_1 = x $ are Bernoulli distributions and can be parametrized as $ \mathcal{Q} = \{\operatorname{Ber}(\expit(\beta x )) \mid \beta \in \mathbb{R}^{k}  \}  $. Now from example \ref{ex:parametricfam} we know that the statistical model, $ \mathcal{P} $, can be parametrized through $ \beta $, in particular we have 
%\begin{align*}
%    P_{\beta}(Y_1= 1 , X_1 \in A) &= \int_{A} Q_{\btheta(x)}(\{1\}) dH_{0}(x)\\
% &= \int_{A} \expit(\beta x )  d H_0(x) 
%\end{align*}
%If $ H_{0} $ has density $ f $ w.r.t. Lebesgue measure, we can write
%\begin{align*}
%    P_{\beta}(Y_1= 1 , X_1 \in A) &= \int_{A} \expit(\beta x ) f(x)  d m(x) 
%\end{align*}
%\end{example}
%We will now turn our attention to statistical estimators. Statistical literature commonly write that an estimator is stochastic variable taking values in our parameter space $ \hat{\btheta} \in \Theta  $. An estimator is achieved by considering i.i.d. observations $ O_1 , \ldots, O_2 \in\mathcal{O} $ distributed according to some measure $ P $ from some statistical model $ \mathcal{P} $. We leave the model unspecified as it can be both parametric or nonparametric. Now let $ h : \mathcal{O}^{n} \to \btheta $ be a measurable map, an estimator created from $ h $ is the random variable $ T = h(O_1 , \ldots, O_n) $. For $ \btheta \subseteq \mathbb{R}^{k} $ the canonical $ \sigma $-algebra on $ \btheta $ is the Borel algebra, but when the parameter set is a set of functions, the $ \sigma $-algebra can only be chosen after careful consideration of constraints on $ \btheta $. 


\section{The Discrete Super Learner}
\subsection{Library of learners}
We would now like to consider the scenario where we have a set of learning algorithms, $ \btheta_1 , \ldots, \btheta_\ml $. From these algorithms, we can define the \textbf{library of learners} $ \lib_{k}(P_n) = \{\btheta_{\q}(P_n) \mid 1 \leq \q \leq \ml \} $ of size $ \ml $. Our goal is to find $ \btheta_{\q}(P_n) $, that achieves the lowest risk among our learners -- that is to provide an estimate of $ \q $ for which $ \q = \argmin_{1 \leq \q \leq \ml} R(\theta_{\q}(P_n) , P) $, we will denote this estimate as $ \hat{q} $.

\subsection{Cross-validation methodology}
To provide $ \hat{\q} $ we have proceed via cross validation. In cross validation, we randomly split our data into a \textbf{training set} and a \textbf{test set}. Let the random binary vector $ S = (S_1,\ldots,S_n) \in \{0,1\}^{n} $ be independent of $ O_1,\ldots, O_n $ such that $ S_i = 0 $ indicates that $ O_i $ should be in the training set and $ S_i = 1 $ indicates that $ O_i $ belongs to the test set. We can define the empirical distributions over these two subsets, $ P_{n,S}^0$ and $ P_{n,S}^{1} $ as
\begin{align*}
    P_{n,S}^{0} &= \frac{1}{n_0} \sum_{i: S_i = 0} \delta_{O_i} \\
    P_{n,S}^{1} &= \frac{1}{n_1} \sum_{i: S_i = 1} \delta_{O_i},
\end{align*}
where $ n_1 = \sum_{i = 1}^{n} S_i, n_0 = 1-n_1$ identifies the number of observations in the test and training set respectively.

\begin{example}[Random splits] \label{splits}
   For $ n $ observations we have $ 2^{n} $ ways of choosing which observations should be in the training set and in the test set. It might not be desirable to define the discrete probabilities for $ S $ over $ \{0,1\}^{n} $ simply as $ \frac{1}{2^{n}} $ for each possible combination of training/test data, since that would also include the combination where $ n_1 = 0 $. To ensure that there is always a certain amount of observations in our test set, let $ n_1 > 0 $ be given, we see that there are $ \begin{pmatrix}
        n \\ n_1
    \end{pmatrix}$ ways of choosing both the test and training set. We can therefore define the distribution of $ S $ as 
    \begin{align*}
        P \left(S = s \right) = \begin{pmatrix}
            n \\ n_1
    \end{pmatrix}^{-1} \qquad \text{for each } s \in \{0,1\}^{n} \text{ where } \sum_{i} s_i = n_1,
    \end{align*}
    this procedure is also known as Monte Carlo cross-validation.
\end{example}

\subsection{Risks and selectors}
We now provide the formal definitions for the expected loss associated with our learners. Recall that the expected $L^2$-loss (\ref{l2risk}) was the integral of the loss with respect to data-generating process $P$. Upon observing our data $D_n$, we can define the empirical risk as the integral of the loss function with respect to $P_n$, as follows
\begin{align*}
    R(\theta , P_n) = \int L(o, \btheta) d P_{n}(o).
\end{align*}
Given a split variable $S$ for our data $D_n$, the risk of our learner on the cross-validation test data can be expressed as
 \begin{align*}
     R(\theta, P_{n, S}^{1}) =  \int L(o, \btheta) d P_{n,S}^{1}(o).
 \end{align*}
 The following definitions are analogous to what is stated in section 1 and 2 of  \cite{laan03}.
 \begin{definition}[Expected loss averaged over splits \cite{vaart06}]
     Given data $D_n$ and a split-variable $S$, the average expected loss for a learner, $\theta_q(P_{n,s}^0)$, from a library $\lib_{\ml}(P_n)$ applied to the training data $P_{n,S}^0$ is
    \begin{align*}
        E_S R( \btheta_\q(P_{n,S}^{0}), P),
    \end{align*}
    where $ P $ is the data-generating process.
\end{definition}
The expectation $ E_S $ is a simple average since $ S $ is discrete. Therefore, for a given $ \q $ we have 
\begin{align*}
    E_S R( \btheta_\q(P_{n,S}^{0}), P) &= \sum_{s \in \{0,1\}^{n}} R(\theta_{q}(P_{n, s}^{0}), P) \cdot P(S = s). 
\end{align*}



\begin{definition}[Oracle selector]
    Given the data $ D_n $ and a split variable $ S $, the oracle selector depends on our data and is the index of the learner with the lowest averaged expected loss 
    \begin{align*}
        \tilde{\q} := \argmin_{1 \leq \q \leq \ml} E_S R( \btheta _\q (P_{n,S}^0 ) , P).
    \end{align*}
\end{definition}
As we are never able to know the oracle, we must proceed via cross-validation to estimate $ \tilde{q}  $. Cross-validation replaces $ P $ with $ P_{n, S}^{1} $ in the second argument of $ R $.
\begin{definition}[Cross-validation expected loss] Given data $D_n$ and a split-variable $S$, the cross-validation expected loss for a learner, $\theta_q(P_{n,s}^0)$, from a library $\lib_{\ml}(P_n)$ applied to the training data $P_{n,S}^0$ is
    \begin{align*}
         E_S R( \btheta_\q(P_{n,S}^{0}), P_{n, S}^{1}),
    \end{align*}
    where $ P_{n,S}^{1} $ is the test data as specified by the split-variable.
\end{definition}

\begin{definition}[Cross-validation selector \cite{laan03}]
    Given the data $ D_n $ and a split variable $ S $, the cross validation selector depends on our data and is the index of the learner with the lowest cross-validation expected loss 
    \begin{align*}
        \hat{\q} := \argmin_{1 \leq \q \leq k}  E_S R( \btheta_\q(P_{n,S}^{0}), P_{n, S}^{1}).
    \end{align*}
\end{definition}
%We are interested in the risk difference between the cross-validation selector and and the oracle selector, we remark that the optimal risk is attained at the true value $ \btheta_0 $ 
%\begin{align*}
%    R(\btheta_0) = \int L(o, \btheta_0)  dP(o),
%\end{align*}
%and clearly it is the case that $ R(\btheta_0) \leq R( \btheta  ) $ for any learner $ \btheta $ of $ \btheta_0 $.
%Given a set of learners we define the centered conditional risk as the difference 
%\begin{align*}
%    \Delta_{S}( \btheta_{ \hat{\q} }, \btheta_0 ) &= R( \btheta _{ \hat{\q} }(P_{n, S}^{0})) -R(\btheta_0) \\
%                                                       &= E_{S} \int L(o, \btheta_{ \hat{\q} }(P_{n, S}^{0})) - L(o, \btheta_0) dP(o) 
%\end{align*}
%
We are now ready to give the definition of the discrete super learner
\begin{definition}[Discrete super learner]
    The \textbf{discrete super learner}, $ \btheta_{ \hat{\q} }(P_n) $, created from a library of learners $ \lib_{k}(P_n) = \{ \btheta_{\q}(P_{n, S}^{0}) \mid 1 \leq \q \leq \ml \}$ is the learner chosen by the cross-validation selector applied to $ D_n $  
    \begin{align*}
        \mathcal{X} \ni x \mapsto \theta_{\hat{\q}}(P_n)(x). 
    \end{align*}
\end{definition}
Formally, the map above is a random map as $ P_n $ is stochastic. Note that in the definition above, $ \hat{q}  $ depends on our data. The discrete super learner is not one specific leaerner among the learners in the library, but the result of after applying the cross-validation selector to the library. 

\subsection{Oracle inequalities}
We introduce the notation $Pf$ for the integral $\int f dP$ of an integrable function $f$ with respect to $P$. Additionally, if $P_n$ represents the empirical measure of $O_1, \dots, O_n$, we denote the empirical process indexed over an appropriate class of functions $\mathcal{F}$ as $G_n f = \sqrt{n}(P_n f - P f)$. Furthermore, we extend this notation to $G_{n, S}^{i} f = \sqrt{n}(P_{n, S}^{i} - Pf)$ for the empirical processes that correspond to applying the empirical measure over either the training data or test data, $ i = 0 $ or $ i = 1 $.

In the following results we assume that a proper loss function $ L: \mathcal{O} \times \Theta \to \mathbb{R} $ has been given.  
\begin{lemma}[Lemma 2.1 in \cite{vaart06}] \label{finitesampledecomp}
    Let $ G_{n} $ be the empirical process of an i.i.d. sample of size $ n $ from the distribution P. For $ \delta > 0 $ it holds that
   \begin{align*}
       E_{S} \int L(o, \btheta_{ \hat{\q}}(P_{n, S}^{0})) dP(o) &\leq (1 + 2 \delta) E_{S} \int L(o, \btheta_{ \tilde{\q} }(P_{n, S}^{0})) d P(o) \\ 
                                                                &+E_{S} \frac{1}{\sqrt{n_1} } \max_{1 \leq \q \leq k} \int L(o, \btheta_{\q}(P_{n, S}^{0})) d ((1 + \delta) G_{n,S}^{1} - \delta \sqrt{n_1} P)(o)  \\
                                                                &+E_{S} \frac{1}{\sqrt{n_1} } \max_{1 \leq \q \leq k} \int-L(o, \btheta_{\q}(P_{n, S}^{0})) d ((1 + \delta) G_{n,S}^{1} + \delta \sqrt{n_1} P)(o)  \\
   \end{align*}
\end{lemma}
\begin{proof}
    See appendix
\end{proof}
To control the bounds for the expected loss we introduce Bernstein pairs 
\begin{definition}[Bernstein pair \cite{vaart06}]
    Given a measurable function $ f: O \to \mathbb{R} $, the tuple $ (M(f) , v(f)) $ is a Bernstein pair if 
    \begin{equation} \label{bernstein}
        M(f)^2 P\left( e^{|f|/M(f)} -1 - \frac{|f|}{|M(f)|}\right) \leq \frac{1}{2}v(f) 
    \end{equation}
\end{definition}
\begin{proposition} \label{unifbernstein}
    $ (\norm{f}_{\infty}, \frac{3}{2} Pf^2 ) $ is a Bernstein pair. 
\end{proposition}
\begin{proof}
    Following proof is due to \cite{vaart06}[ch. 8.1]. 
    \begin{align*}
        \norm{f}_{\infty}^2 P\left( e^{|f|/\norm{f}_{\infty}} -1 - \frac{|f|}{\norm{f}_{\infty}}\right) &= \norm{f}_{\infty}^{2} \sum_{k \geq 2}^{\infty} P \frac{|f|^{k}}{\norm{f}^{k}_{\infty}k!} = Pf^2 \sum_{k \geq 2}^{\infty} P\frac{|f|^{k-2}}{\norm{f}^{k-2}_{\infty} k! } \\
                                                                                                        &\leq P f^2 \sum_{k \geq 2}^{\infty} \frac{\norm{f}_{\infty}^{k-2}}{\norm{f}^{k-2}_{\infty} k! } = P f^2 \sum_{k \geq 2}^{\infty} \frac{1}{k !}\\
                                                                                                        &= P f^2 (e-2)\leq \frac{3}{4} P f^2 = \frac{1}{2} \left(\frac{3}{2} Pf^2\right). 
    \end{align*}
   In the first inequality we replace the absolute value of $ f $ with the uniform norm, which is larger. 
\end{proof}


\begin{lemma}[Lemma 2.2 in \cite{vaart06}] \label{finitesamplebound}
    Let $G_{n}$ be the empirical process of an i.i.d. sample of size $n$ from the distribution $P$ and assume that $P f \geq 0$ for every $f \in \mathcal{F}$ in some set of measurable functions $ \mathcal{F} $ on $ \mathcal{O} $. Then, for any Bernstein pair $(M(f), v(f))$ and for any $\delta>0$ and $1 \leq p \leq 2$,
    \begin{align*}
        E_{D_n} \max_{f \in \mathcal{F}}(G_n-\delta \sqrt{n} P) f \leq \frac{8}{n^{1 / p-1 / 2}} \log (1+\# \mathcal{F}) \max _{f \in \mathcal{F}}\left[\frac{M(f)}{n^{1-1 / p}}+\left(\frac{v(f)}{(\delta P f)^{2-p}}\right)^{1 / p}\right].
    \end{align*}
    The same upper bound is valid for $ E_{D_n} \max_{f \in \mathcal{F}}(G_n+\delta \sqrt{n} P)(-f) $  
\end{lemma}
The expectation above is wrt. the joint probability measure over our observations, $ D_n \sim P_{O}^{n} = P_{O_1} \otimes P_{O_2} \otimes \dots \otimes P_{O_n} $. 

\begin{theorem}[Theorem 2.3 in \cite{vaart06}] \label{finitesample}
   For $ \btheta \in \Theta $ let $ (M(\btheta) , v(\btheta)) $ be a Bernstein pair for the function $ o \mapsto L(o, \btheta) $ and assume that $ R(\btheta, P) \geq 0 $ for every $ \btheta \in \Theta $. Then for $ \delta > 0 $ and $ 1 \leq p \leq 2 $ it holds that 
   \begin{align*}
       E_{D_n} E_{S} R(\btheta_{\hat{\q}}(P_{n, S}^{0}), P) \leq&(1 + 2 \delta) E_{D_n} E_{S} R(\btheta_{ \tilde{\q}}(P_{n,S}^{0}), P) +\\
                                                                &(1 + \delta) E_S \left(  \frac{16}{n_1^{1/p}} \log (1 +k) \sup_{\btheta \in \Theta} \left[ \frac{M(\btheta)}{n_1^{1-1/p}} +  \left( \frac{v(\btheta)}{R(\btheta, P)^{2-p}} \right)^{1/p} \left( \frac{1 + \delta}{\delta} \right)^{2/p-1} \right]\right),
   \end{align*}
   where $ k $ is the number of learners in our library $ \{\btheta_{\q}(P_{n, S}^{0}) \mid 1 \leq \q \leq k\} $ and $ S $ is a split-variable. 
\end{theorem}
In the expectations above, we are taking the expectation wrt. the random split-variable $ S $ as well as the joint distribution of our observations. In a more verbose manner one would write 
\begin{align*}
     E_{S} E_{D_n}  R(\btheta_{\hat{\q}}(P_{n, S}^{0}), P) = \int R(\btheta_{ \hat{q} }(P_{n, S}^{0}), P) d (P_S \otimes  P^{n}_O ).
\end{align*}

\begin{proof}[Proof]
    We will apply lemma \ref{finitesamplebound} to the second and third terms on the left hand side of the inequality in lemma \ref{finitesampledecomp}. Let $ \mathcal{F} = \{o \mapsto L(o, \btheta_{\q}(P_{n,S}^{0})) \mid 1 \leq \q \leq \ml\}$, be the collection of functions obtained by applying the loss $ L $ to each learner in our library of $ \ml $ learners. Note that $ \mathcal{F} \subseteq \{o \mapsto L(o, \btheta) \mid \btheta \in \Theta\} $, and since $ R(\btheta, P) \geq 0 $ for every $ \btheta \in \Theta $ it follows that $ Pf \geq 0 $ for every $ f \in \mathcal{F} $.

First, we take the expectation wrt. $ D_n $ on both sides in lemma \ref{finitesampledecomp}. For the second term we have 
\begin{align*}
&E_{D_n} E_{S} \frac{1}{\sqrt{n_1} } \max_{1 \leq \q \leq k} \int L(o, \btheta_{\q}(P_{n, S}^{0})) d ((1 + \delta) G_{n,S}^{1} - \delta \sqrt{n_1} P)(o)\\
&= 
E_{D_n}E_{S} \frac{1 + \delta}{\sqrt{n_1} } \max_{1 \leq \q \leq k} \int L(o, \btheta_{\q}(P_{n, S}^{0})) d (G_{n,S}^{1} - \frac{\delta }{1 + \delta} \sqrt{n_1} P)(o)\\
&=E_{S} \frac{1 + \delta}{\sqrt{n_1} } E_{D_n}\max_{1 \leq \q \leq k} \int L(o, \btheta_{\q}(P_{n, S}^{0})) d (G_{n,S}^{1} - \frac{\delta }{1 + \delta} \sqrt{n_1} P)(o).
\end{align*}
Where we use Fubini in the last equality. Recall that $ S \indep D_n $, so we can always consider $ n_1 $ as fixed given $ D_n $, now applying lemma \ref{finitesamplebound} to the expression above with $ n = n_1 $ yields 
\begin{align*}
&E_S\frac{1 + \delta}{\sqrt{n_1} } E_{D_n} \max_{1 \leq \q \leq k} \int L(o, \btheta_{\q}(P_{n, S}^{0})) d (G_{n,S}^{1} - \frac{\delta }{1 + \delta} \sqrt{n_1} P)(o) \\
&\leq E_S \frac{1 + \delta}{\sqrt{n_1}} \frac{8}{n_1^{1/p-1/2}} \log(1 + k) \max_{1 \leq \q \leq k} \left[ \frac{M(\btheta_{\q}(P_{n,S}^{0}))}{n_1^{1-1/p}} + \left( \frac{v(\btheta_{ \q}(P_{n,S}^0) )}{( \frac{\delta}{1 + \delta} )^{2-p} R(\btheta_{\q}(P_{n,S}^{0}), P)^{2-p}} \right)^{1/p} \right] \\
&\leq E_S\frac{1 + \delta}{\sqrt{n_1}} \frac{8}{n_1^{1/p-1/2}} \log(1 + k) \sup_{\btheta \in \Theta} \left[ \frac{M(\btheta)}{n_1^{1-1/p}} + \left( \frac{v(\btheta)}{( \frac{\delta}{1 + \delta} )^{2-p} R(\btheta,P)^{2-p}} \right)^{1/p} \right] \\
&= (1 + \delta) E_S\frac{8}{n_1^{1/p}} \log(1 + k) \sup_{\btheta \in \Theta} \left[ \frac{M(\btheta)}{n_1^{1-1/p}} + \left( \frac{v(\btheta)}{R(\btheta,P)^{2-p}} \right)^{1/p}\left( \frac{1 + \delta}{\delta}  \right)^{2/p-1} \right]  
\end{align*}
Where for the third inequality we take the $ \sup $ over $ \Theta $. We can also bound the third term with the same expression above as lemma \ref{finitesamplebound} is also valid for $ -L $. It is now immediate from lemma \ref{finitesampledecomp} that 
\begin{align*}
    E_{D_n} E_{S} &\int L(o, \btheta_{ \hat{\q} }(P_{n, S}^{0})) d P(o) \leq (1 + 2 \delta) E_{D_n} E_{S} \int L(o, \btheta_{ \tilde{\q} }(P_{n, S}^{0})) d P(o) \\
                                                               &+ (1 + \delta) E_S\frac{8}{n_1^{1/p}} \log(1 + k) \sup_{\btheta \in \Theta} \left[ \frac{M(\btheta)}{n_1^{1-1/p}} + \left( \frac{v(\btheta)}{R(\btheta)^{2-p}} \right)^{1/p}\left( \frac{1 + \delta}{\delta}  \right)^{2/p-1} \right]\\
                                                               &+ (1 + \delta) E_S\frac{8}{n_1^{1/p}} \log(1 + k) \sup_{\btheta \in \Theta} \left[ \frac{M(\btheta)}{n_1^{1-1/p}} + \left( \frac{v(\btheta)}{R(\btheta)^{2-p}} \right)^{1/p}\left( \frac{1 + \delta}{\delta}  \right)^{2/p-1} \right],
\end{align*}
The second and third terms above are identical, meaning that they can be combined into one term where the numerator in the first fraction is $ 16 $ instead of $ 8 $. 
\end{proof}

\begin{corollary}[Asymptotic equivalence] 
   The risk of the super learner is asymptotically equivalent to the risk of the oracle estimator. That is,
   \begin{align*}
       \lim_{n \to \infty} \frac{E_{D_n} E_S R(\btheta_{ \hat{\q} }(P_{n, S}^{0}), P)}{E_{D_n} E_S R(\btheta_{ \tilde{\q} }(P_{n, S}^{0}), P)} = 1 
   \end{align*}
\end{corollary}
\begin{proof}
    By choosing $ p = 2 $ in theorem \ref{finitesample}, we obtain
    \begin{align*}
        E_{D_n} E_S R(\btheta_{\hat{\q}}(P_{n, S}^{0}), P) &\leq(1 + 2 \delta) E_{D_n} E_{S} R(\btheta_{ \tilde{\q}}(P_{n,S}^{0}), P)\\
                                                        &+(1 + \delta) E_S \frac{16}{\sqrt{n_1}} \log (1 +k) \sup_{\btheta \in \Theta} \left[ \frac{M(\theta)}{\sqrt{n_1}} + \sqrt{v(\theta)} \right].
    \end{align*}
    In the above inequality, so long as the $ n_1 $ is monotonically increasing as $ n $ increases, the remainder term goes to $ 0 $. Now by dividing the oracle risk on both sides, we obtain
    \begin{align*}
        \frac{E_{D_n} E_S R(\btheta_{\hat{\q}}(P_{n, S}^{0}), P)}{E_{D_n} E_{S} R(\btheta_{ \tilde{\q}}(P_{n,S}^{0}), P)} &\leq 1 + 2 \delta + \frac{1 + \delta}{E_{D_n} E_{S} R(\btheta_{ \tilde{\q}}(P_{n,S}^{0}), P)} E_S \frac{16}{\sqrt{n_1}} \log (1 +k) \sup_{\btheta \in \Theta} \left[ \frac{M(\theta)}{\sqrt{n_1}} + \sqrt{v(\theta)} \right].
    \end{align*}
    As the inequality holds for all $ \delta > 0 $, we can choose $ \delta $ to depend on $ n $ or just set it to 0. The problem now lies in assesing how fast the oracle risk converges, see that by setting $ \delta = 0 $ the inequality becomes 
    \begin{align*}
     \frac{E_{D_n} E_S R(\btheta_{\hat{\q}}(P_{n, S}^{0}), P)}{E_{D_n} E_{S} R(\btheta_{ \tilde{\q}}(P_{n,S}^{0}), P)} &\leq 1 + \frac{E_S \frac{16}{\sqrt{n_1}} \log (1 +k) \sup_{\btheta \in \Theta} \left[ \frac{M(\theta)}{\sqrt{n_1}} + \sqrt{v(\theta)} \right]}{E_{D_n} E_{S} R(\btheta_{ \tilde{\q}}(P_{n,S}^{0}), P)} 
    \end{align*}
    The fraction on the left-hand side will converge to $0$ so long as the remainder (numerator) is $o$ of the oracle risk, or if the oracle risk converges to a number strictly greater than $ 0 $. We also note that by the definition of the oracle, we have 
    \begin{align*}
        E_{D_n} E_{S} R(\btheta_{ \tilde{\q}}(P_{n,S}^{0}), P) \leq E_{D_n} E_{S} R(\btheta_{ \tilde{\q}}(P_{n,S}^{0}), P),
    \end{align*}
    implying that 
        \begin{align*}
        1 \leq \frac{E_{D_n} E_S R(\btheta_{\hat{\q}}(P_{n, S}^{0}), P)}{E_{D_n} E_{S} R(\btheta_{ \tilde{\q}}(P_{n,S}^{0}), P)}. 
    \end{align*}
    Applying the squeeze theorem thus yields the desired result. 
\end{proof}

\subsection{Example: asymptotic equality}
Let $ D_n $ be our data distributed according some $ P \in \mathcal{P} $. Our goal is to estimate the conditional expectation 
\begin{align*}
   x \mapsto E(Y \mid X = x) = P(Y = 1 \mid X = x) 
\end{align*}
Consider the quadratic loss function $ L((Y, X), \btheta) = (Y - \btheta(X))^2 $ for this task. 

We observe that the quadratic loss is bounded by $ 1 $ for all choices of $ \btheta \in \Theta $ and $ O \in \mathcal{O} $. It follows from proposition \ref{unifbernstein} that $ M(\btheta) = 1 $ and $ v(\btheta) = \frac{3}{2} \int L(o, \btheta)^2 dP(o)  $ is a valid Bernstein pair for the function $ o \mapsto L(o, \btheta)$. It is also clear that $ R(\btheta) = \int L(o , \btheta) d P(o) \geq 0  $ since the loss function is positive. 

We now have the choice of choosing $p $ in theorem \ref{finitesample}. By choosing $ p = 2 $, we see that we obtain a bound of order $ O(n^{-1/2}) $ on the remainder. We can also choose $ p = 1 $, which yields a bound of order $ O(n^{-1}) $ for every fixed $ \delta > 0$. A smart choice of $ p $ will yield a tighter finite sample bound in conjunction with choosing $ \delta $ to depend on $ n $. It is described in \cite{vaart06} that the oracle risk can be of order $ O(n^{-1}) $ in settings where one of the learners in our library corresponds to a finite-dimensional model containing our true regression function. 
For asymptotic applications, however, this does not matter. By choosing $ p = 2 $ we observe that our bound simplifies to 
\begin{align*}
   ER(\btheta_{\hat{\q}}(P_{n, S}^{0})) &\leq(1 + 2 \delta) ER(\btheta_{ \tilde{\q}}(P_{n,S}^{0})) +(1 + \delta) E \left(  \frac{16}{\sqrt{n_1}} \log (1 +k) \sup_{\btheta \in \Theta} \left[ \frac{M(\theta)}{\sqrt{n_1}} + \sqrt{v(\theta)} \right]\right),
\end{align*}
now by setting $\delta = 0$, we obtain 
\begin{align*}
   ER(\btheta_{\hat{\q}}(P_{n, S}^{0})) &\leq ER(\btheta_{ \tilde{\q}}(P_{n,S}^{0})) + E \left(  \frac{16}{\sqrt{n_1}} \log (1 +k) \sup_{\btheta \in \Theta} \left[ \frac{M(\theta)}{\sqrt{n_1}} + \sqrt{v(\theta)} \right]\right).
\end{align*}
By assuming that $ n_1 $ increases as $ n $ increases, the above result shows that the risk of our super learner is the risk of the oracle plus a remainder term which goes to zero at a rate of $1/\sqrt{n}$. Recall that the learner selected by oracle selector is by denfinition the learner with the lowest risk in our library, that is
\begin{align*}
   ER(\btheta_{ \tilde{\q}}(P_{n,S}^{0})) \leq ER(\btheta_{\hat{\q}}(P_{n, S}^{0})).
\end{align*}
By applying the squeeze theorem, we can conclude that the super learner achieves a risk that is asymptotically equivalent to the oracle.  

% \subsubsection{Choosing $p = 1$}
% \begin{align*}
%    ER(\btheta_{\hat{\q}}(P_{n, S}^{0})) &\leq(1 + 2 \delta) ER(\btheta_{ \tilde{\q}}(P_{n,S}^{0})) +(1 + \delta) E \left(  \frac{16}{n_1} \log (1 +k) \sup_{\btheta \in \Theta} \left[ M(\btheta) + \frac{v(\btheta)}{R(\btheta)} \frac{1 + \delta}{\delta}\right]\right)
% \end{align*}
% In the equation provided, we observe that we can manipulate the following variables: sample size $n$, validation set size $n_1$, parameter $\delta > 0$, and the number of learners $k$. Assuming $k$ remains constant, the validation set size $n_1$ could be either stochastic, depending on the split variable $S$, or fixed as a constant, as illustrated in example \ref{splits}. For instance, we can set $n_1 = n/2$. By establishing a fixed value for $n_1$, we can drop the expectation in the second term. 

% The supremum on the left side of the equation might increase significantly because $R(\btheta)$ could be very small. However, by carefully selecting the value of $v(\btheta)$, we can avoid the fraction from growing too large. Note that for any $ \btheta \in \Theta $:
% \begin{align*}
%     \frac{v(\btheta)}{R(\btheta)} = \frac{3}{2} \frac{\int L(o, \btheta)^2 d P(o)}{\int L(o, \btheta) dP(o)  } \leq \frac{3}{2} \frac{\int L(o, \btheta) \cdot 1 dP(o) }{\int L(o, \btheta) dP(o) } = \frac{3}{2},
% \end{align*}
% by using $ 0 \leq L(o, \btheta) \leq 1 $ almost surely. Since $ M(\btheta) $ is constant for all $ \btheta \in \Theta $, it is possible to drop the supremum. Combining all the information above we obtain 
% \begin{align*}
%    ER(\btheta_{\hat{\q}}(P_{n, S}^{0})) &\leq(1 + 2 \delta) ER(\btheta_{ \tilde{\q}}(P_{n,S}^{0})) +(1 + \delta) \frac{16}{n_1} \log (1 +k) \left[ 1 + \frac{3}{2} \frac{1 + \delta}{\delta}\right]\\
%                                         &= (1 + 2 \delta) ER(\btheta_{ \tilde{\q}}(P_{n,S}^{0})) +\log (1 +k) \frac{3 + 5\delta}{2\delta}(1 + \delta) \frac{16}{n_1} \\
%                                         &= (1 + 2 \delta) ER(\btheta_{ \tilde{\q}}(P_{n,S}^{0})) +\log (1 +k) \frac{3 + 8\delta + 5 \delta^2}{2\delta}\frac{16}{n_1} \\\
%                                         &= (1 + 2 \delta) ER(\btheta_{ \tilde{\q}}(P_{n,S}^{0})) +\log (1 +k) \left( \frac{3}{2\delta} + 4 + \frac{5}{2} \delta \right) \frac{16}{n_1},
% \end{align*}
% We can now adjust for the precision in our bound by choosing $ \delta $ and $ n $. Note that a small delta will mean that the first term $ (1 + 2 \delta) E R(\btheta_{ \tilde{q} }(P_{n, S}^{0})) $ will become smaller, but this is at the expense that the remainder term becomes larger due to the $ \frac{1 + \delta}{ \delta} $ fraction at the end. By choosing $ n $ to be large, we can partially compensate for a smaller delta.

% We might, therefore, for each $ n $, choose the $ \delta_n $ that minimizes the left-hand side for the given $ n $. By substituting $ n_1 = n/2 $ into the left hand side expression and then expanding it we obtain 
% \begin{align*}
%  ER(\btheta_{ \tilde{\q}}(P_{n,S}^{0})) + 2 \delta ER(\btheta_{ \tilde{\q}}(P_{n,S}^{0})) +\frac{3}{2\delta}\log (1 +k) \frac{32}{n} + 4\log (1 +k) \frac{32}{n} + \frac{5\delta}{2} \log (1 +k)   \frac{32}{n},
% \end{align*}
% we observe that when $n$ is fixed, two terms remain constant, specifically the first and fourth terms, as they do not depend on $\delta$. The optimal $\delta_n$ can be determined as follows:
% \begin{align*}
%     \delta_n &= \argmin_{\delta} \frac{1}{\delta} \cdot \frac{3 \cdot 32}{2n} \log(1 + k) + \delta \cdot \left(2ER(\btheta_{ \tilde{\q} }(P_{n, S}^{0})) + \frac{5 \cdot 32}{2n} \log(1 + k) \right) \\
%     &= \argmin_{\delta} \frac{1}{\delta} \cdot \frac{48}{n} \log(1 + k) + \delta \cdot \left(2ER(\btheta_{ \tilde{\q} }(P_{n, S}^{0})) + \frac{80}{n} \log(1 + k) \right) \\
%     &= \argmin_{\delta} \frac{1}{\delta} a(n) + \delta b(n),
% \end{align*}
% Essentially, solving for the minimum is a convex optimization problem, with the terms $a(n) = \frac{48}{n} \log(1 + k)$ and $b(n) = 2ER(\btheta_{ \tilde{\q} }(P_{n, S}^{0})) + \frac{80}{n} \log(1 + k)$ remaining constant with respect to $n$. By differentiating the expression above and setting it equal to zero we obtain 
% \begin{align*}
%     0 &= \left( \frac{1}{\delta} a(n) + \delta b(n) \right)' = - \frac{1}{\delta^2} a(n) + b(n),
% \end{align*}
% and so we obtain the optimum by isolating $ \delta $ 
% \begin{align*}
%     \delta_n = \sqrt{\frac{a(n)}{b(n)}}. 
% \end{align*}
% We see that $ a(n) $ converges at a rate of order $ 1/n $ to 0 and the rate of $ b(n) $ depends on the unknown oracle risk. For $ n \to \infty $, the risk term $ 2ER(\theta_{ \tilde{q} }(P_{n, S}^{0})) $ converges to the lowest possible risk achievable by any of the learners, it might be the case that the convergence is fast, i.e. it converges at a rate of order $ 1/n^{-1/2} $. That is if  
% \begin{align*}
%     \delta_n = \sqrt{\frac{a(n)}{b(n)}} = \sqrt{\frac{\frac{48}{n} \log(1 + k)}{O(\frac{1}{\sqrt{n}}) + \frac{80}{n} \log(1 + k) }} = \sqrt{\frac{48 \log(1 + k)}{O(\sqrt{n}) + 80 \log(1 + k)}}
% \end{align*}


%Nonetheless, obtaining a useful bound could be challenging unless $n$ is considerably large. In that case, the oracle risk might be extremely close to the true risk. Unless the remainder constitutes only a minuscule portion of the oracle risk, the finite sample result may not be of significant interest.
%
%To illustrate the problem, consider a concrete example where we might model $ ER(\btheta_{ \tilde{\q} }(P_{n, S}^{0})) $ as a simple function, $ f(n) $, that is monotonically decreasing for $ n \to \infty $. For example
%\begin{align*}
%    f(n)= \frac{1}{2\sqrt{n}} \qquad \text{for }  n \in \mathbb{N} 
%\end{align*}
%which steadily decreases to $ 0 $, but is bounded by $ 0.5 $. 
%
%We now have the choice of solving for $ \delta $ given $ n $, or vice-versa. We might for example be interested in our cross-validation risk to be at most $ 2\% $ more than our oracle risk, which amounts to selecting $ \delta = 0.01 $, we will then solve for $ n $ for an acceptable size on the remainder. For some $ \gamma \in (0, 1) $ which represents the tolerable proportion of our oracle risk that our remainder term can at most attain, and $ \delta = 0.01$, we wish to solve  $ n $ in the following 
%\begin{align*}
%    1.02  \gamma \cdot f(n) \geq \log (1 + k) \frac{154.025 \cdot 16 }{n_1} =  \log (1 + k) \frac{154.025 \cdot 16 }{\frac{n}{2}} = \log (1 + k) \frac{4928.8}{n},
%\end{align*}
%which is equivalent to 
%\begin{align*}
%    \frac{\log (1 + k) \cdot 4928.8}{1.02 \gamma } \leq f(n) \cdot n = \frac{n}{2 \sqrt{n}} = \frac{\sqrt{n}}{ 2} .
%\end{align*}
%For $ k = 5 $ and $ \gamma = 0.01 $, the left hand side is around 865806, multiplying this number by 3 and then squaring it yields us $n = 2998480118544 $, at this point, the oracle risk is $ f(n) \approx 5 \cdot 10^{-26}$. 

%The following result is due to \cite{laan03}: 
%\begin{theorem}[Asymptotic equality]
%    The cross validation selector $ \hat{\q} $ performs asymptotically as well as the oracle selector $ \tilde{\q} $ in the sense that 
%    \begin{align*}
%        \frac{\Delta_{S}( \btheta_{ \hat{\q} } , \btheta_0 )}{ \Delta_{S}( \btheta_{ \tilde{\q} } , \btheta_0) } \to 1 \qquad \text{ in probability for } n \to \infty
%    \end{align*}
%\end{theorem}


\section{The Ensemble Super Learner}
\section{Simulation results}
In the following section we show the results of applying the discrete super learner to a simulated dataset. Our dataset consists of a binary outcome, $Y$, which depends on two covariates $X_1$ and $X_2$. Our setup is as follows
\begin{align*}
    X_1 &\sim \operatorname{Unif}(0.5, 15),\\
    X_2 \mid X_1 = x_1 &\sim \mathcal{N}(3.5-0.03x_1, 1),\\
    Y \mid X_1 = x_1, X_2 = x_2 &\sim \operatorname{Ber}(\theta_0(x_1, x_2)),
\end{align*}
for $\theta_0(x_1, x_2) = \expit({-3.5 - 0.3x_1 + 0.85x_2 + 0.35x_1x_2})$ which is the true regression function. The true regression function is captured by the logistic regression model with interaction terms. We would like to learn the true regression using the discrete super learner. We use the following libraries of learners as an illustrative example:
\begin{enumerate}
    \item Intercept only logistic regression: $E[Y \mid X_1, X_2] = \expit(\beta_0)$
    \item Logistic regression with main effects: $E[Y \mid X_1, X_2] = \expit(\beta_0 + \beta_1 X_1 + \beta_2 X_2)$
    \item XGBoost with hyperparameters: \texttt{max\_depth=3, eta=0.3,\\ n\_rounds=100, objective='binary:logistic', booster='dart', nthread=5}
\end{enumerate}
Our goal is to estimate $\theta_0$
\subsection{Simulation results for the discrete super learner}
We now show the loss of the discrete super learner compared to the other learners. We use the following loss function
\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{figures/dsl_loss.png}
    \caption{The loss of the discrete super learner compared to other learners. $ N = 3600 $}
\end{figure}



\section{Discussion}
Hello 
\printbibliography

\end{document}
