\documentclass[11pt, a4paper]{article}
\usepackage[margin=3cm]{geometry} 
\usepackage[english, science, hyperref]{ku-frontpage}
\usepackage[utf8]{inputenc}
\usepackage{amsmath,amssymb,amsthm,bm}
\usepackage{mdframed}
\usepackage{mathtools}
\usepackage[
    backend=biber,
    style=alphabetic
]{biblatex}
\bibliography{references.bib}

\setlength\parindent{0pt}
\DeclareMathOperator*{\argmax}{arg\,max} 
\DeclareMathOperator*{\argmin}{arg\,min}

\newtheorem{theorem}{Theorem}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{remark}{Remark}

\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\theoremstyle{remark}
\usepackage{mdframed}

\mdfdefinestyle{examplestyle}{%
    linewidth=1pt,
    innerleftmargin=10pt,
    innerrightmargin=10pt,
    skipabove=10pt, % add vertical space above
    skipbelow=10pt, % add vertical space below
    frametitlefont=\bfseries,
    nobreak=true
}
\newtheorem{example}{Example}
\surroundwithmdframed[style=examplestyle]{example}


\setlength\arraycolsep{2 pt}
\setcounter{tocdepth}{2}
\setcounter{secnumdepth}{2}

\newcommand{\cl}{q}
\newcommand{\btheta}{h}
\newcommand{\empmod}{\mathcal{P}_{\text{emp}}}
\DeclareMathOperator{\expit}{expit}

\assignment{A Bachelor of Science thesis}
\author{Jinyang Liu}


\title{Super Learners}
\subtitle{and their oracle properties}
\date{Submitted: \today}
\advisor{Supervised by Prof. Thomas Gerds\\ Co-supervised by Prof. Niels Richard Hansen \\Department of Mathematical Sciences \\University of Copenhagen, Denmark}
% \frontpageimage{example.png}

\begin{document}
\begingroup
    \fontencoding{T1}\fontfamily{lmr}\selectfont
    \maketitle
    \tableofcontents
    \newpage
\endgroup


\section{Introduction}
Our setup closely models what is described in \cite{vaart06} and \cite{laan03}. 
Let $ O_1, \ldots, O_n $ be $ n $-i.i.d. observations distributed according to $ P \in \mathcal{P} $ on some measurable space $ (\mathcal{O}, \mathcal{A}) $ where $ O_{i} \in \mathcal{O} $ for each $ i $ and $ \mathcal{P} $ is our statistical model. For a parameter set $ \Theta $ we define the corresponding loss function $ L : \mathcal{O} \times \Theta \to [0, \infty) $ as a measurable map such that our goal is to find an estimator $ \hat{\theta}  $ that minimizes the true risk function $ R: \Theta \to \mathbb{R} $ given as
\begin{align*}
    R(\theta) = \int L(x, \theta)  dP(x) = EL(O_1) 
\end{align*}
The parameter set $ \Theta $ can be Euclidean, but for the focus of this thesis we will consider it as a collection of functions of the form $ \theta : \mathcal{O} \to \mathbb{R} $. 

\begin{example}[Regression functions $ \Theta $] \label{ex:regfunc}
    Let $ O_1 = (Y_1 , X_1) ,\ldots, O_n = (Y_n , X_n) \in  \mathcal{O} = \mathbb{R} \times \mathcal{X} $ be i.i.d. observations distributed according to some $ P \in \mathcal{P} $ such that they satisfy the model 
    \begin{align*}
        Y_1 = \theta_0(X_1) + \varepsilon,
    \end{align*}
    for an unobservable stochastic error term $ \varepsilon $. The goal is to estimate an unknown \textbf{regression function} $ \theta_0 \in \Theta $ where $ \Theta = \{\theta \mid \theta : \mathcal{X} \to \mathbb{R}\}$, is the set of possible regression functions each having $ \mathcal{X} $ as their domain. \cite{vaart06}
\end{example}
\begin{example}[Parameteric family] \label{ex:parametricfam}
    Consider the initial setup from example \ref{ex:regfunc}. If $ Y_i $ is $ \mathcal{B}(\mathbb{R})-\mathcal{B}(\mathbb{R}) $ measurable and $ X_i $ is $ \mathcal{F} - \mathcal{B}(\mathbb{R})  $ measurable for some sigma-algebra $ \mathcal{F} $ on $ \mathcal{X} $, then a \textbf{generalized regression model} could be considered as parametrized family of distributions, $ \mathcal{P} = \{P_{\theta} \mid \theta \in \Theta\} $, given that $ \Theta $ is finite-dimensional.

    We can parametrize the conditional probability distributions for $ Y_1 $ given $ X_1 = x $ as $ \mathcal{Q} = \{Q_{\theta(x)} \mid \theta \in \Theta \} $ such that $ Q_{\theta(x)} $ is a valid probability distribution on $ \mathcal{B}(\mathbb{R}) $ for each $ x \in X $ and $ \theta \in \Theta $. For a given $ P_{\theta} \in \mathcal{P} $ there will exist a $ Q_{\theta} \in \mathcal{Q} $ such that  
    \begin{align*}
        P_{\theta}(Y \in A \mid X = x) = Q_{ \theta(x)}(A) \qquad \text{for all } A \in \mathcal{B}(\mathbb{R}).
    \end{align*}
    If we assume that $ X_1 $ is distributed according to some $ H_0 $ on $ \mathcal{X} $, then the distribution $ P_{\theta} $ over our observations (the joint over $ Y $ and $ X $) will be
    \begin{align*}
        P_{\theta }(X \in A, Y \in B ) = \int_{A} Q_{\theta(x)}(B) d H_{0}(x) 
    \end{align*}
    for every $ A \in \mathcal{F} $ and $ B \in \mathcal{B}(\mathbb{R}) $. 
\end{example}
\begin{example}[Logistic regression model] \label{logregmod}
    Let $ O_1 = (Y_1 , X_n) , \ldots, O_n = (Y_n , X_n) \in \mathcal{O} = \{0,1\} \times \mathcal{X} $ be i.i.d. observations from some distribution $ P_{\theta_0} \in \mathcal{P} $, where $ Y_i $ is binary and $ \mathcal{X} \subseteq \mathbb{R}^{k} $. We would like to estimate the parameter function $ \theta_{0} \in \Theta $
\begin{align*}
    \theta_0(x) = E(Y_1 \mid X_1 = x) = P_{\theta_0}(Y_1 = 1 \mid X_1 = x),
\end{align*}
In logistic regression we assume that $ \Theta = \{x \mapsto \expit(\beta x) \mid \beta \in \mathbb{R}^{k}\} $, so $ \theta_0(x) = \expit(\beta_0 x) $, then the goal becomes to estimate the $ k $-dimensional parameter $ \beta_0 $, in this case the $ \mathbb{R}^{k} $ parameter $ \beta_0  $ completely determines $ \theta_0 $, so $ \Theta $ is also $ k $-dimensional. % I am not sure if the last is true

The conditional distributions of $ Y_1 $ given $ X_1 = x $ are Bernoulli distributions and can be parametrized as $ \mathcal{Q} = \{\operatorname{Ber}(\expit(\beta x )) \mid \beta \in \mathbb{R}^{k}  \}  $. Now from example \ref{ex:parametricfam} we know that the statistical model, $ \mathcal{P} $, can be parametrized through $ \beta $, in particular we have 
\begin{align*}
    P_{\beta}(Y_1= 1 , X_1 \in A) &= \int_{A} Q_{\theta(x)}(\{1\}) dH_{0}(x)\\
 &= \int_{A} \expit(\beta x )  d H_0(x) 
\end{align*}
If $ H_{0} $ has density $ f $ w.r.t. Lebesgue measure, we can write
\begin{align*}
    P_{\beta}(Y_1= 1 , X_1 \in A) &= \int_{A} \expit(\beta x ) f(x)  d m(x) 
\end{align*}
\end{example}
We will now turn our attention to statistical estimators. Statistical literature commonly write that an estimator is stochastic variable taking values in our parameter space $ \hat{\theta} \in \Theta  $. An estimator is achieved by considering i.i.d. observations $ O_1 , \ldots, O_2 \in\mathcal{O} $ distributed according to some measure $ P $ from some statistical model $ \mathcal{P} $. We leave the model unspecified as it can be both parametric or nonparametric. Now let $ h : \mathcal{O}^{n} \to \Theta $ be a measurable map, an estimator created from $ h $ is the random variable $ T = h(O_1 , \ldots, O_n) $. For $ \Theta \subseteq \mathbb{R}^{k} $ the canonical $ \sigma $-algebra on $ \Theta $ is the Borel algebra, but when the parameter set is a set of functions, the $ \sigma $-algebra can only be chosen after careful consideration of constraints on $ \Theta $. 

In the following section we introduce the terminology ``estimator algorithm'' which corresponds to the measurable map $ h $ from our finite sample observation space to our parameter space. 
\begin{definition}[Estimator algorithm $ \btheta $]
    An estimator algorithm is a measurable map $ \btheta : \mathcal{O}^{n} \to \Theta $ for $ n \in \mathbb{N} $. 
\end{definition}
\begin{definition}[Statistical Estimator $ \hat{\theta} $]
    Let $ O_1, \ldots, O_n \in \mathcal{O} $ be i.i.d. observations distributed according to some $ P \in \mathcal{P} $ for a statistical model $ \mathcal{P} $ on $ \mathcal{O} $. Let $ \btheta : \mathcal{O}^{n} \to \Theta $ be an estimator algorithm. An estimator is the random variable $ \hat{\theta} = \btheta(O_1 ,\ldots , O_n) \in \Theta $. 
\end{definition}
There is a one-to-one correspondence between the tuples of i.i.d. observations $ (O_1 , \ldots, O_n) \in \mathcal{O}^{n} $ and the empirical measures over $ n $ observations on $ (\mathcal{O} , \mathcal{A}) $ defined as  
\begin{align*}
    P_n(A) = \frac{1}{n} \sum_{i = 1}^{n} \delta_{O_i}(A)\qquad \text{ for } A \in \mathcal{A}.
\end{align*}
Note that the empirical measure is a random variable. Thus, we can write $ \btheta(P_n)$ as an alternative representation of the estimator $\btheta(O_1, \ldots, O_n)$, by adjusting the notation without introducing ambiguity. 

\begin{example}[Prediction algorithm] 
    Consider the setup from example \ref{logregmod}, where we have i.i.d. observations $ O_1 = (Y_1 , X_1) ,\ldots, O_n = (Y_n , X_n) $ such that $ Y_i \in \{0,1\} $ and $ \mathcal{X}\in \mathbb{R}^{k} $ and our goal is to estimate the probability $ \theta(x) = P_{\theta}(Y_1 = 1 \mid X_1 = x ) $...
\end{example}
We would now like to consider the scenario where we have a library (set) of learner algorithms, $ \btheta_1 , \ldots, \btheta_n $. From these algorithms, we can define the set of learners $ \{ \hat{\theta} _{\cl} = \btheta_{\cl}(P_n) | 1 \leq \cl \leq p \} $, where our goal is to find $ \hat{\theta}_{ \hat{\cl} }(P_n) $, which denotes the learner that minimizes $ R $ and $ \hat{\cl}  $ may depend on the observations. 

In order to find $ \hat{\cl}  $ we have to proceed via cross validation. In cross validation, we randomly split our data into a training set and a test set. Let the random binary vector $ S = (S_1,\ldots,S_n) \in \{0,1\}^{n} $ be independent of $ X_1,\ldots, X_n $ such that $ S_i = 0 $ indicates that $ X_i $ should be in the training set and $ S_i = 1 $ indicates that $ X_i $ belongs to the test set. We can define the empirical distributions over these two subsets, $ P_{n,S}^0$ and $ P_{n,S}^{1} $ as
\begin{align*}
    P_{n,S}^{0} &= \frac{1}{n_0} \sum_{i: S_i = 0} \delta_{X_i} \\
    P_{n,S}^{1} &= \frac{1}{1-n_0} \sum_{i: S_i = 1} \delta_{X_i} 
\end{align*}
Where $ n_0 $ would be the number of $ S_i $'s that are marked $ 0 $. 

\begin{example}[Random splits]
    For $ n = 9 $ observations one could for example define the distribution of the random vector $ S $ as 
   \begin{align*}
       P(S = (0, 0, 0, 0, 0, 0, 1, 1, 1)) &= \frac{1}{3} \\
       P(S = (0, 0, 0, 1, 1, 1, 0, 0, 0)) &= \frac{1}{3} \\
       P(S = (1, 1, 1, 0, 0, 0, 0, 0, 0)) &= \frac{1}{3},
   \end{align*}
    i.e. 3-fold cross-validation.

    In general for $ n $ observations we have $ 2^{n} $ ways of choosing which observations should be in the training set and in the validation set. It might not be desirable to define the discrete probabilities for $ S $ over $ \{0,1\}^{n} $ simply as $ \frac{1}{2^{n}} $ for each possible combination of training/validation data, since that would also include the combination where $ n_1 = 0 $. To ensure that we always have $ n_1 > 0 $, then let $ n_1 $ be given, then we see that there are $ \begin{pmatrix}
        n \\ n_1
    \end{pmatrix}$ ways of choosing both the validation and training set. We can therefore define the distribution of $ S $ as 
    \begin{align*}
        P \left(S = s \right) = \begin{pmatrix}
            n \\ n_1
    \end{pmatrix}^{-1} \qquad \text{for each } s \in \{0,1\}^{n} \text{ where } \sum_{i} s_i = n_1
    \end{align*}

\end{example}


\begin{definition}[True risk of $ \cl $'th learner averaged over splits]
    Given the data $ O_1, \ldots, O_n \in \mathcal{O} $ and a set of learners $ \{ \theta_{\cl}(P_{n, S}^{0}) \mid 1 \leq \cl \leq p \}, p \in \mathbb{N} $ applied to our training data $ P_{n, S}^{0} $. The risks of these learners averaged over some split-variable $ S $ is given as a function of $ \cl $ 
    \begin{align*}
        \cl \mapsto E_S \int L(x, \theta_{\cl}(P_{n,S}^{0}) ) dP(x) = E_S R( \theta_\cl(P_{n,S}^{0})) 
    \end{align*}
    Where $ P $ is the true distribution for our data $ X $.
\end{definition}

\begin{definition}[Oracle selector]
    The oracle selector is a function $ \tilde{\cl}: \mathcal{O}^{n} \to \{1,\ldots,p\} $  which finds the learner that minimizes the true risk given our data $ O_1 , \ldots , O_n \in O$. 
    \begin{align*}
        \tilde{\cl}(O_1 , \ldots, O_n) = \argmin_{1 \leq \cl \leq p} E_S R( \theta _\cl (P_{n,S}^0 )) 
    \end{align*}
    Where $ P_{n ,s}^{0} $ is the empirical distribution over the training set of $O_1 , \ldots, O_n $ as specified by some split-variable $ S $. 
\end{definition}
In similar manner to the above the defintions, we can define the cross-validation risk and the cross-validation selector for our learners 

\begin{definition}[Cross-validation risk of $ i $'th learner averaged over splits]
    Given the data $ O_1, \ldots, O_n \in \mathcal{O} $ and a set of learners $ \{ \theta_{\cl}(P_{n, S}^{n}) \mid 1 \leq \cl \leq p \}, p \in \mathbb{N} $. The cross-validation risks of these learners averaged over some split-variable $ S $ is given as a function of $ \cl $ 
    \begin{align*}
        \cl \mapsto E_S \int L(x, \theta_{\cl}(P_{n,S}^{0}) ) dP_{n, s}^{1}(x) = E_S \hat{R}( \theta_\cl(P_{n,S}^{0})) 
    \end{align*}
    Where $ P_{n,S}^{1} $ is the empircal distribution over the validation of $ O_1 , \dots, O_n $. We write $ \hat{R} $ for the empirical risk over the validation set. 
\end{definition}

\begin{definition}[Cross-validation selector]
    The cross-validation selector is a function $ \hat{\cl}: \mathcal{O}^{n} \to \{1,\ldots,p\} $  which finds the learner that minimizes the cross-validation risk given our data $ O_1 , \dots , O_n \in \mathcal{O} $. 
    \begin{align*}
        \hat{\cl}(O_1 , \dots , O_n) = \argmin_{1 \leq \cl \leq p} E_S \hat{R} ( \theta _\cl (P_{n,S}^0 )) 
    \end{align*}
    Where $ \hat{R}  $ is the empirical risk over the validation set and $ P_{n ,s}^{0} $ is the empirical distribution over the training set of $ O_1 , \dots , O_n  $ as specified by some split-variable $ S $. 
\end{definition}
We are interested in the risk difference between the cross-validation selector and and the oracle selector, we remark that the optimal risk is attained at the true value $ \theta_0 $ 
\begin{align*}
    R(\theta_0) = \int L(x, \theta_0)  dP(x),
\end{align*}
and clearly it is the case that $ R(\theta_0) \leq R( \theta  ) $ for any learner $ \theta $ of $ \theta_0 $.
Given a set of learners we define the centered conditional risk as the difference 
\begin{align*}
    \Delta_{S}( \theta_{ \hat{\cl} }, \theta_0 ) &= R( \theta _{ \hat{\cl} }(P_{n, S}^{0})) -R(\theta_0) \\
                                                       &= E_{S} \int L(x, \theta_{ \hat{\cl} }(P_{n, S}^{0})) - L(x, \theta_0) dP(x) 
\end{align*}

The following result is due to \cite{laan03}: 
\begin{theorem}[Asymptotic equality]
    The cross validation selector $ \hat{\cl} $ performs asymptotically as well as the oracle selector $ \tilde{\cl} $ in the sense that 
    \begin{align*}
        \frac{\Delta_{S}( \theta_{ \hat{\cl} } , \theta_0 )}{ \Delta_{S}( \theta_{ \tilde{\cl} } , \theta_0) } \to 1 \qquad \text{ in probability for } n \to \infty
    \end{align*}
\end{theorem}


\section{The discrete super learner, dSL}

\subsection{Finite sample properties}

\section{The ensemble super learner, eSL}
\section{Simulation results}
\section{Discussion}
Pellentesque tincidunt sodales risus, vulputate iaculis odio dictum vitae. Ut ligula tortor, porta a consequat ac, commodo non risus. Nullam sagittis luctus pretium. Integer vel nibh at justo convallis imperdiet sit amet ut lorem. Sed in gravida turpis. Vestibulum ante ipsum primis in faucibus orci luctus et ultrices posuere cubilia Curae; Sed in massa vitae ligula pellentesque feugiat vitae in risus. Cras iaculis tempus mi, sit amet viverra nulla viverra pellentesque.



\end{document}
