\documentclass[11pt, a4paper]{article}
\usepackage[margin=3cm]{geometry} 
\usepackage[english, science, hyperref]{ku-frontpage}
\usepackage[utf8]{inputenc}
\usepackage{amsmath,amssymb,amsthm,bm}
\usepackage{mdframed}
\usepackage{mathtools}
\usepackage[
    backend=biber,
    style=alphabetic
]{biblatex}
\bibliography{references.bib}

\setlength\parindent{0pt}
\DeclareMathOperator*{\argmax}{arg\,max} 
\DeclareMathOperator*{\argmin}{arg\,min}

\newtheorem{theorem}{Theorem}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{remark}{Remark}

\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\theoremstyle{remark}
\usepackage{mdframed}

\mdfdefinestyle{examplestyle}{%
    linewidth=1pt,
    innerleftmargin=10pt,
    innerrightmargin=10pt,
    skipabove=10pt, % add vertical space above
    skipbelow=10pt, % add vertical space below
    frametitlefont=\bfseries,
    nobreak=true
}
\newtheorem{example}{Example}
\surroundwithmdframed[style=examplestyle]{example}


\setlength\arraycolsep{2 pt}
\setcounter{tocdepth}{2}
\setcounter{secnumdepth}{2}

\newcommand{\q}{q}
\newcommand{\ml}{k}
\newcommand{\btheta}{\theta}
\newcommand{\lib}{\hat{\Theta}}
\newcommand{\empmod}{\mathcal{P}_{\text{emp}}}
\DeclareMathOperator{\expit}{expit}

\assignment{A Bachelor of Science thesis}
\author{Jinyang Liu}


\title{Super Learners}
\subtitle{and their oracle properties}
\date{Submitted: \today}
\advisor{Supervised by Prof. Thomas Gerds\\ Co-supervised by Prof. Niels Richard Hansen \\Department of Mathematical Sciences \\University of Copenhagen, Denmark}
% \frontpageimage{example.png}

\begin{document}
\begingroup
    \fontencoding{T1}\fontfamily{lmr}\selectfont
    \maketitle
    \tableofcontents
    \newpage
\endgroup


\section{Introduction}
In the context of prediction, the goal is to estimate the conditional expectation $ E(Y \mid X = x) $ for i.i.d. observation pairs $ (Y_1 , X_1) , \dots , (Y_n , X_n) $. Depending on the data structure, a variety of standard statistical models can be employed. For instance, if Y is binary, a parametric model like logistic regression might be suitable.
The task of identifying true statistical model $ \mathcal{P} $ for which $ (Y, X) \sim P \in \mathcal{P} $, is challenging, and perhaps infeasible when we only have a limited amount data. It may therefore be motivating ot utilize non-parametric and data-driven regression methods, such as tree-based algorithms like XGBoost or random forests to estimate the conditional mean. However, the underlying assumptions of tree-ensemble methods regarding the data generating process are not explicit, and they may not have probabilistic interpretations. We can nevertheless incorporate these methods as a part of our repertoire, but it is important that we can compare and choose the best method that most effectively accompishes our goal, for example prediction. 

The 'super learner' is the answer to how we can effectively select the 'best' learner (method or algorithm) among the learners that we have in our library of learners. The cross-validation selector, which evaluates learners on their cross-validated (empirical) risk and chooses the one with the lowest risk, is asymptotically equivalent to the oracle selector. The oracle selector finds the learner with the lowest true risk -- the risk obtained by knowing the true distribution. 

The discrete super learner is obtained by applying the cross-validation selector on our data. The asymptotic result shows that the cross-validation selector will select the same learner as the oracle selector when the number of observations goes to $ \infty $. The discrete super learner is not a fixed learner from our library, but rather depends on the available data. It represents the learner chosen by the cross-validation selector, which can vary depending on the amount of data at hand.

We first present the general theory and our goal, which is to estimate the conditional expectation $ E(Y \mid X = x) $ for $ Y, X $ being some outcome-covariate pair. More specifically, we focus on the case where we regress on a binary outcome $ Y \in \{0,1\} $. The conditional expectation of $ Y $ given $ X $ exactly becomes the conditional probability $ P(Y = 1 \mid X = x) $.


\section{Background}

Our setup closely models what is described in \cite{vaart06} and \cite{laan03}. Unless specified otherwise, our setup is as follows:
Let statistical model $ \mathcal{P} $ be given on the measurable space $ (\mathcal{O}, \mathcal{A}) $ where $ \mathcal{O} = \{0,1\} \times \mathcal{X} $ is our sample space for some $ \mathcal{X} \subseteq \mathbb{R}^{d} $. 
%Let $ O_1 = (Y_1 , X_1), \ldots, O_n = (Y_n, X_n) \in \mathcal{O} = \{0,1\} \times \mathcal{X} $ be $ n $-i.i.d. observations distributed according to $ P \in \mathcal{P} $ on some measurable space $ (\mathcal{O}, \mathcal{A}) $.
We will consider the parameter set $ \btheta = \{\btheta \mid \btheta : \mathcal{X} \to [0,1]\} $, which represents the set of regression functions that map from our covariates to the probability interval. We define the quadratic loss and the corresponding risk that we wish to minimize 
\begin{definition}[Quadratic loss]
    Let $ \mathcal{O}  $ be our sample space, and $ \btheta $ be the set of regression functions. Then the quadratic loss or $ L^2 $-loss, $ L : \mathcal{O} \times \btheta \to [0, \infty) $, for an observation $ o \in \mathcal{O} $ and a regression function $ \btheta \in \btheta $ is defined as 
\begin{align*}
    L(o, \btheta) = L((y,x), \btheta) = (y - \btheta(x))^2.
\end{align*}
\end{definition}
Our natural aim would be to find the optimal parameter value $\btheta^* \in \btheta$ that minimizes the $L^2$-risk $R: \btheta \to \mathbb{R}$ given as 
\begin{equation} \label{l2risk}
    R(\btheta) := \int L(o, \btheta)  dP(o) = EL(O, \btheta),
\end{equation}
but this task is challenging as it requires us to know the data-generating process, $ P $, which we do not have accesss to. It can be shown that the minimum risk is achieved by the conditional probability $ x \mapsto P(Y = 1\mid X = x) $. 
\begin{theorem}
    Let $ (\mathcal{O} , \mathcal{A}, P) $ be a probability space for some probability measure $ P \in \mathcal{P} $. Let $ \btheta $ be the set of regression functions of the form $ \btheta : \mathcal{X} \to [0,1] $. Let the loss function be the $ L^2 $-loss $ L(o, \btheta) = (y - \btheta(x))^2 $, then for the optimimum $ \btheta^* $ defined as 
    \begin{align*}
        \btheta^* := \argmin_{\btheta \in \btheta} R(\btheta)= \argmin_{\btheta \in \btheta} \int L(o, \btheta)  dP(o),
    \end{align*}
    it holds for an observation $ O = (Y, X) \sim P $ that
    \begin{align*}
        \btheta^{*}(x) = E(Y \mid X = x) 
    \end{align*}
\end{theorem}
\begin{proof}
    See \cite{gyorfi2002distribution}[ch. 1]
\end{proof}
It follows immediately that if $ Y $ is binary, then $ E(Y \mid X = x) = P(Y = 1 \mid X = x) $.  
In the case where we do not have access to the data-generating process, we would instead want to provide an estimate $ \hat{\btheta} $ of $ \btheta^*$ as a function of the data that we have observed. Let $ O_1 = (Y_1 , X_1) ,\ldots, O_n = (Y_n , X_n) \in  \mathcal{O} $ be i.i.d. observations distributed according to some $ P \in \mathcal{P} $. Denote our data as $ D_n = (O_1, \dots , O_n)$. An estimate is the outcome of applying an estimator to the data 
\begin{align*}
    D_n \mapsto \hat{\btheta}(D_n) \in \Theta,   
\end{align*}
The estimate is a regression function, that is 
\begin{align*}
    \mathcal{X} \ni x \mapsto \hat{\btheta}(D_n)(x) \in [0,1].
\end{align*}
In the context of super learners we will refer the estimators as learners, in the sense that they learn from the data, the resulting regression function is then the fit of the learner to the data. We formalize these notions in the subsequent section. 


%\begin{example}[Regression functions $ \btheta $] \label{ex:regfunc}
%    Let $ O_1 = (Y_1 , X_1) ,\ldots, O_n = (Y_n , X_n) \in  \mathcal{O} = \mathbb{R} \times \mathcal{X} $ be i.i.d. observations distributed according to some $ P \in \mathcal{P} $ such that they satisfy the model 
%    \begin{align*}
%        Y_1 = \btheta_0(X_1) + \varepsilon,
%    \end{align*}
%    for an unobservable stochastic error term $ \varepsilon $. The goal is to estimate an unknown \textbf{regression function} $ \btheta_0 \in \btheta $ where $ \btheta = \{\btheta \mid \btheta : \mathcal{X} \to \mathbb{R}\}$, is the set of possible regression functions each having $ \mathcal{X} $ as their domain. \cite{vaart06}
%\end{example}
%\begin{example}[Parametric statistical model] \label{ex:parametricfam}
%    In the case where we have $ n $-i.i.d. observations distributed according to some data-generating process $ P \in \mathcal{P} $, we have that each $ O_i = (Y_i , X_i) $, and $ X_i $ is a stochastic variable. The distribution $ P $ factorizes essentially into two parts, the conditional distribution of $ Y $ given $ X $ and the background distribution of $ X $, so $ P = P_{Y \mid X = x} \cdot P_X $. In this setup we are doing estimation with random design \cite{gyorfi2002distribution}.  
%
%We can formalize the setup as follows: $ O = (Y, X) \sim P $, if $ Y $ is $ \mathcal{B}(\mathbb{R})-\mathcal{B}(\mathbb{R}) $ measurable and $ X $ is $ \mathcal{F} - \mathcal{B}(\mathbb{R})  $ measurable for some sigma-algebra $ \mathcal{F} $ on $ \mathcal{X} $, then a \textbf{generalized regression model} could be considered as parametrized family of distributions, $ \mathcal{P} = \{P_{\btheta} \mid \btheta \in \btheta\} $, given that $ \btheta $ is finite-dimensional.
%
%    We can parametrize the conditional probability distributions for $ Y_1 $ given $ X_1 = x $ as $ \mathcal{Q} = \{Q_{\btheta(x)} \mid \btheta \in \btheta \} $ such that $ Q_{\btheta(x)} $ is a valid probability distribution on $ \mathcal{B}(\mathbb{R}) $ for each $ x \in X $ and $ \btheta \in \btheta $. For a given $ P_{\btheta} \in \mathcal{P} $ there will exist a $ Q_{\btheta} \in \mathcal{Q} $ such that  
%    \begin{align*}
%        P_{\btheta}(Y \in A \mid X = x) = Q_{ \btheta(x)}(A) \qquad \text{for all } A \in \mathcal{B}(\mathbb{R}).
%    \end{align*}
%    If we assume that $ X_1 $ is distributed according to some $ H_0 $ on $ \mathcal{X} $, then the distribution $ P_{\btheta} $ over our observations (the joint over $ Y $ and $ X $) will be
%    \begin{align*}
%        P_{\btheta }(X \in A, Y \in B ) = \int_{A} Q_{\btheta(x)}(B) d H_{0}(x) 
%    \end{align*}
%    for every $ A \in \mathcal{F} $ and $ B \in \mathcal{B}(\mathbb{R}) $. 
%\end{example}
%\begin{example}[Logistic regression model] \label{logregmod}
%    Let $ O_1 = (Y_1 , X_n) , \ldots, O_n = (Y_n , X_n) \in \mathcal{O} = \{0,1\} \times \mathcal{X} $ be i.i.d. observations from some distribution $ P_{\btheta_0} \in \mathcal{P} $, where $ Y_i $ is binary and $ \mathcal{X} \subseteq \mathbb{R}^{k} $. We would like to estimate the parameter function $ \btheta_{0} \in \btheta $
%\begin{align*}
%    \btheta_0(x) = E(Y_1 \mid X_1 = x) = P_{\btheta_0}(Y_1 = 1 \mid X_1 = x),
%\end{align*}
%In logistic regression we assume that $ \btheta = \{x \mapsto \expit(\beta x) \mid \beta \in \mathbb{R}^{k}\} $, so $ \btheta_0(x) = \expit(\beta_0 x) $, then the goal becomes to estimate the $ k $-dimensional parameter $ \beta_0 $, in this case the $ \mathbb{R}^{k} $ parameter $ \beta_0  $ completely determines $ \btheta_0 $, so $ \btheta $ is also $ k $-dimensional. % I am not sure if the last is true
%
%The conditional distributions of $ Y_1 $ given $ X_1 = x $ are Bernoulli distributions and can be parametrized as $ \mathcal{Q} = \{\operatorname{Ber}(\expit(\beta x )) \mid \beta \in \mathbb{R}^{k}  \}  $. Now from example \ref{ex:parametricfam} we know that the statistical model, $ \mathcal{P} $, can be parametrized through $ \beta $, in particular we have 
%\begin{align*}
%    P_{\beta}(Y_1= 1 , X_1 \in A) &= \int_{A} Q_{\btheta(x)}(\{1\}) dH_{0}(x)\\
% &= \int_{A} \expit(\beta x )  d H_0(x) 
%\end{align*}
%If $ H_{0} $ has density $ f $ w.r.t. Lebesgue measure, we can write
%\begin{align*}
%    P_{\beta}(Y_1= 1 , X_1 \in A) &= \int_{A} \expit(\beta x ) f(x)  d m(x) 
%\end{align*}
%\end{example}
%We will now turn our attention to statistical estimators. Statistical literature commonly write that an estimator is stochastic variable taking values in our parameter space $ \hat{\btheta} \in \btheta  $. An estimator is achieved by considering i.i.d. observations $ O_1 , \ldots, O_2 \in\mathcal{O} $ distributed according to some measure $ P $ from some statistical model $ \mathcal{P} $. We leave the model unspecified as it can be both parametric or nonparametric. Now let $ h : \mathcal{O}^{n} \to \btheta $ be a measurable map, an estimator created from $ h $ is the random variable $ T = h(O_1 , \ldots, O_n) $. For $ \btheta \subseteq \mathbb{R}^{k} $ the canonical $ \sigma $-algebra on $ \btheta $ is the Borel algebra, but when the parameter set is a set of functions, the $ \sigma $-algebra can only be chosen after careful consideration of constraints on $ \btheta $. 


\section{The Discrete Super Learner}

In the following section we introduce the terminology \textbf{learning algorithm} and \textbf{learners} in the context of learning from our data.  

\subsection{Learning algorithm}
\begin{definition}[Learning algorithm $ \btheta $]
    An learning algorithm is a measurable map $ \btheta : \mathcal{O}^{n} \to \btheta $ for $ n \in \mathbb{N} $. 
\end{definition}

We use the notation $ \btheta $ for the learning algorithm, which coincides with the notation for a regression function that resides in $ \btheta $. Indeed, it makes sense in our context since for $ D_n = (O_1 , \dots , O_n) $ being our data, we would like to express the outcome of applying a learning algorithm to our data, $\btheta(D_n) $, we refer to that as the \textbf{fitted learner} which is in $ \btheta $.  

However, we must remark that formally, $ \btheta(D_n) $ is a stochastic variable since $ D_n $ is stochastic. It is, therefore, a map from a background space, $ \Omega $, to the parameter space, $ \btheta $. In practice, we would have observed $ O_3(\omega) = o_1, \dots, O_n(\omega) = o_n $ for a specific omega, and subsequently, we can fit our learning algorithm on $ D_n(\omega) $, which is a particular instance of a dataset. The fitted learner, $ \btheta(D_n(\omega)) $, is a regression function in $ \btheta $. The abuse in notation is analogous to stating that ``$ X \in \mathbb{R} $'' for a real random variable $ X $, even though this is not technically correct since $ X $ is a measurable map rather than a real number.
\begin{example}[Parametric and nonparametric learning algorithms]
    An example of a parametric learner is logistic regression, and an example of a nonparametric learner is the tree-based gradient boosting algorithm XGBoost, which has many hyperparametrs that can be tuned, and the fitted parameters are not directly interpretable.  
\end{example}
There is a one-to-one correspondence between our data $ D_n = (O_1 , \ldots, O_n) $ and the empirical measures over $ n $ observations on $ (\mathcal{O} , \mathcal{A}) $ defined as
\begin{align*}
    P_n(A) = \frac{1}{n} \sum_{i = 1}^{n} \delta_{O_i}(A)\qquad \text{ for } A \in \mathcal{A}.
\end{align*}
We can, therefore, write $ \btheta(P_n)$ as an alternative representation of the learner $\btheta(D_n)$, by adjusting the notation slightly without introducing ambiguity. The motivation for using this notation will become clearer in the subsequent section, where we introduce the cross-validation selector.

\subsection{Library of learners}
We would now like to consider the scenario where we have a library (set) of learning algorithms, $ \btheta_1 , \ldots, \btheta_n $. From these algorithms, we can define the library of learners $ \lib = \{ \hat{\btheta}_\q = \btheta_{\q}(P_n) \mid 1 \leq \q \leq \ml \} $. Once again, our natural goal is to find $ \hat{\btheta} $, that achieves the lowest risk among our learners, that is to find $ \q $ such that $ R( \hat{\btheta_{\q}} ) = \min_{ \hat{\btheta}  \in \hat{\Theta} } R( \hat{\btheta} ) $. But as we have remarked before, this is not possible unless we know the data-generating process $ P $, instead we can only provide an estimate $ \hat{\q} $ of $ q $ that is based on our data.


\subsection{Cross-validation methodology}
To provide the estimate $ \hat{\q} $ we have proceed via cross validation. In cross validation, we randomly split our data into a training set and a test set. Let the random binary vector $ S = (S_1,\ldots,S_n) \in \{0,1\}^{n} $ be independent of $ O_1,\ldots, O_n $ such that $ S_i = 0 $ indicates that $ O_i $ should be in the training set and $ S_i = 1 $ indicates that $ O_i $ belongs to the test set. We can define the empirical distributions over these two subsets, $ P_{n,S}^0$ and $ P_{n,S}^{1} $ as
\begin{align*}
    P_{n,S}^{0} &= \frac{1}{n_0} \sum_{i: S_i = 0} \delta_{O_i} \\
    P_{n,S}^{1} &= \frac{1}{n_1} \sum_{i: S_i = 1} \delta_{O_i} 
\end{align*}
Where $ n_0, n_1 $ would be the number of $ S_i $'s that are marked $ 0 $ and $ 1 $ respectively. 

\begin{example}[Random splits] \label{splits}
    For $ n = 9 $ observations one could for example define the distribution of the random vector $ S $ as 
   \begin{align*}
       P(S = (0, 0, 0, 0, 0, 0, 1, 1, 1)) &= \frac{1}{3}, \\
       P(S = (0, 0, 0, 1, 1, 1, 0, 0, 0)) &= \frac{1}{3}, \\
       P(S = (1, 1, 1, 0, 0, 0, 0, 0, 0)) &= \frac{1}{3},
   \end{align*}
    i.e. 3-fold cross-validation.
    In general for $ n $ observations we have $ 2^{n} $ ways of choosing which observations should be in the training set and in the validation set. It might not be desirable to define the discrete probabilities for $ S $ over $ \{0,1\}^{n} $ simply as $ \frac{1}{2^{n}} $ for each possible combination of training/validation data, since that would also include the combination where $ n_1 = 0 $. To ensure that we always have a certain amount of observations in our validation set, let $ n_1 > 0 $ be given, we see that there are $ \begin{pmatrix}
        n \\ n_1
    \end{pmatrix}$ ways of choosing both the validation and training set. We can therefore define the distribution of $ S $ as 
    \begin{align*}
        P \left(S = s \right) = \begin{pmatrix}
            n \\ n_1
    \end{pmatrix}^{-1} \qquad \text{for each } s \in \{0,1\}^{n} \text{ where } \sum_{i} s_i = n_1,
    \end{align*}
    this procedure is also known as Monte Carlo cross-validation.
\end{example}

\subsection{Risks and selectors}
We now provide the formal definitions for the risks associated with our learners. Recall that the $L^2$-risk (\ref{l2risk}) was the integral of the loss with respect to data-generating process $P$. Upon observing our data $D_n$, we can define the empirical risk as the integral of the loss function with respect to $P_n$, as follows
\begin{align*}
    \hat{R}(\btheta) := \int L(o, \btheta) d P_{n}(o).
\end{align*}
 Now let some split variable $ S $ be given for our data $ D_n $, we are also interested in how our learner performs on the cross-validation data. Denote the risk of our learner on the cross-validation data as 
 \begin{align*}
     \hat{R}_S(\theta) :=  \int L(o, \btheta) d P_{n,S}^{1}(o).
 \end{align*}
 


\begin{definition}[True risk of $ \q $'th learner averaged over splits]
    Given the data $ D_n $ and some split-variable $ S $. The risk of each learner in a specified library, $ \hat{\Theta} = \{ \btheta_{\q}(P_{n, S}^{0}) \mid 1 \leq \q \leq \ml \}, \ml \in \mathbb{N} $, applied to our training data $ P_{n, S}^{0} $ and averaged over each possible split can be calculated by
    \begin{align*}
        \q \mapsto E_S \int L(o, \btheta_{\q}(P_{n,S}^{0}) ) dP(o) = E_S R( \btheta_\q(P_{n,S}^{0})) 
    \end{align*}
    Where $ P $ is the true distribution for our data $ X $.
\end{definition}
The expectation $ E_S $ is a simple average since $ S $ is discrete. Therefore, for a given $ \q $ we have 
\begin{align*}
    E_S R( \btheta_\q(P_{n,S}^{0})) &= \frac{1}{| \operatorname{supp}(S)|} \sum_{s \in \operatorname{supp}(S)} R(\theta_{q}(P_{n, S = s}^{0}))
\end{align*}



\begin{definition}[Oracle selector]
    The oracle selector is a function $ \tilde{\q}: \mathcal{O}^{n} \to \{1,\ldots,k\} $  which finds the learner that minimizes the true risk given our data $ D_n $. 
    \begin{align*}
        \tilde{\q}(D_n) := \argmin_{1 \leq \q \leq \ml} E_S R( \btheta _\q (P_{n,S}^0 )) 
    \end{align*}
    Where $ P_{n ,s}^{0} $ is the empirical distribution over the training set of $D_n $ as specified by some split-variable $ S $. 
\end{definition}
In similar manner to the above the defintions, we can define the cross-validation risk and the cross-validation selector for our learners 

\begin{definition}[Cross-validation risk]
    Given the data $ D_n $ and some split-variable $ S $. The cross-validation risk of a learner in a specified library, $ \hat{\Theta} = \{ \btheta_{\q}(P_{n, S}^{0}) \mid 1 \leq \q \leq k \}, k \in \mathbb{N} $, applied to our training data $ P_{n, S}^{0} $ is  
    \begin{align*}
        \q \mapsto E_S \hat{R}_S( \btheta_\q(P_{n,S}^{0})).
    \end{align*}
\end{definition}

\begin{definition}[Cross-validation selector]
    The cross-validation selector is a function $ \hat{\q}: \mathcal{O}^{n} \to \{1,\ldots,k\} $  which finds the learner that minimizes the cross-validation risk given our data $ D_n $
    \begin{align*}
        \hat{\q}(D_n) := \argmin_{1 \leq \q \leq k} E_S \hat{R}_S ( \btheta _\q (P_{n,S}^0 )). 
    \end{align*}
\end{definition}
%We are interested in the risk difference between the cross-validation selector and and the oracle selector, we remark that the optimal risk is attained at the true value $ \btheta_0 $ 
%\begin{align*}
%    R(\btheta_0) = \int L(o, \btheta_0)  dP(o),
%\end{align*}
%and clearly it is the case that $ R(\btheta_0) \leq R( \btheta  ) $ for any learner $ \btheta $ of $ \btheta_0 $.
%Given a set of learners we define the centered conditional risk as the difference 
%\begin{align*}
%    \Delta_{S}( \btheta_{ \hat{\q} }, \btheta_0 ) &= R( \btheta _{ \hat{\q} }(P_{n, S}^{0})) -R(\btheta_0) \\
%                                                       &= E_{S} \int L(o, \btheta_{ \hat{\q} }(P_{n, S}^{0})) - L(o, \btheta_0) dP(o) 
%\end{align*}
%
\subsection{Oracle inequalities}
We introduce the notation $Pf$ for the integral $\int f dP$ of an integrable function $f$ with respect to $P$. Additionally, if $P_n$ represents the empirical measure of $O_1, \dots, O_n$, we denote the empirical process indexed over an appropriate class of functions $\mathcal{F}$ as $G_n f = \sqrt{n}(P_n f - P f)$. Furthermore, we extend this notation to $G_{n, S}^{i} f = \sqrt{n}(P_{n, S}^{i} - Pf)$ for the empirical processes that correspond to applying the empirical measure over either the training sample or validation sample.

In the following results we assume that a proper loss function $ L: \mathcal{O} \times \btheta \to \mathbb{R} $ has been given.  
\begin{lemma}[Lemma 2.1 in \cite{vaart06}] \label{finitesampledecomp}
    Let $ G_{n} $ be the empirical process of an i.i.d. sample of size $ n $ from the distribution P. For $ \delta > 0 $ it holds that
   \begin{align*}
       E_{S} \int L(o, \btheta_{ \hat{\q}}(P_{n, S}^{0})) dP(o) &\leq (1 + 2 \delta) E_{S} \int L(o, \btheta_{ \tilde{\q} }(P_{n, S}^{0})) d P(o) \\ 
                                                                &+\frac{1}{\sqrt{n_1} } E_{S} \max_{1 \leq \q \leq k} \int L(o, \btheta_{\q}(P_{n, S}^{0})) d ((1 + \delta) G_{n,S}^{1} - \delta \sqrt{n_1} P)(o)  \\
                                                                &+\frac{1}{\sqrt{n_1} } E_{S} \max_{1 \leq \q \leq k} \int-L(o, \btheta_{\q}(P_{n, S}^{0})) d ((1 + \delta) G_{n,S}^{1} + \delta \sqrt{n_1} P)(o)  \\
   \end{align*}
\end{lemma}
\begin{proof}
    See appendix
\end{proof}

\begin{lemma}[Lemma 2.2 in \cite{vaart06}] \label{finitesamplebound}
    Let $G_{n}$ be the empirical process of an i.i.d. sample of size $n$ from the distribution $P$ and assume that $P f \geq 0$ for every $f \in \mathcal{F}$. Then, for any Bernstein pairs $(M(f), v(f))$ and for any $\delta>0$ and $1 \leq p \leq 2$,
    \begin{align*}
    E \max_{f \in \mathcal{F}}(G_n-\delta \sqrt{n} P) f \leq \frac{8}{n^{1 / p-1 / 2}} \log (1+\# \mathcal{F}) \max _{f \in \mathcal{F}}\left[\frac{M(f)}{n^{1-1 / p}}+\left(\frac{v(f)}{(\delta P f)^{2-p}}\right)^{1 / p}\right].
    \end{align*}
    The same upper bound is valid for $ E \max_{f \in \mathcal{F}}(G_n+\delta \sqrt{n} P)(-f) $  
\end{lemma}

\begin{theorem}[Finite Sample Result: Theorem 2.3 in \cite{vaart06}] \label{finitesample}
   For $ \btheta \in \btheta $ let $ (M(\btheta) , v(\btheta)) $ be a Bernstein pair for the function $ o \mapsto L(o, \btheta) $ and assume that $ R(\btheta) = \int L(o, \btheta) d P(o) \geq 0 $ for every $ \btheta \in \btheta $. Then for $ \delta > 0 $ and $ 1 \leq p \leq 2 $ it holds that 
   \begin{align*}
       ER(\btheta_{\hat{\q}}(P_{n, S}^{0})) \leq&(1 + 2 \delta) ER(\btheta_{ \tilde{\q}}(P_{n,S}^{0})) +\\
                                              &(1 + \delta) E \left(  \frac{16}{n_1^{1/p}} \log (1 +k) \sup_{\btheta \in \btheta} \left[ \frac{M(\btheta)}{n_1^{1-1/p}} +  \left( \frac{v(\btheta)}{R(\btheta)^{2-p}} \right)^{1/p} \left( \frac{1 + \delta}{\delta} \right)^{2/p-1} \right]\right),
   \end{align*}
   where $ k $ is the number of learners in our library $ \{\btheta_{\q}(P_{n, S}^{0}) \mid 1 \leq \q \leq k\} $. 
\end{theorem}

\begin{proof}
    We will apply lemma \ref{finitesamplebound} to the second and third terms on the left hand side of the inequality in lemma \ref{finitesampledecomp}. Let $ \mathcal{F} = \{o \mapsto L(o, \btheta_{\q}(P_{n,S}^{0})) \mid 1 \leq \q \leq k\}$, be the collection of functions obtained by applying the loss $ L $ to each learner in our libary of $ k $ learners. Note that $ \mathcal{F} \subseteq \{o \mapsto L(o, \btheta) \mid \btheta \in \btheta\} $, and since $ R(\btheta) \geq 0 $ for every $ \btheta \in \btheta $ it follows that $ Pf \geq 0 $ for every $ f \in \mathcal{F} $. 
   
For the second term we have 
\begin{align*}
&\frac{1}{\sqrt{n_1} } E_{S} \max_{1 \leq \q \leq k} \int L(o, \btheta_{\q}(P_{n, S}^{0})) d ((1 + \delta) G_{n,S}^{1} - \delta \sqrt{n_1} P)(o)\\
&= 
\frac{1 + \delta}{\sqrt{n_1} } E_{S} \max_{1 \leq \q \leq k} \int L(o, \btheta_{\q}(P_{n, S}^{0})) d (G_{n,S}^{1} - \frac{\delta }{1 + \delta} \sqrt{n_1} P)(o),
\end{align*}
applying lemma \ref{finitesamplebound} to the expression above yields 
\begin{align*}
&\frac{1 + \delta}{\sqrt{n_1} } E_{S} \max_{1 \leq \q \leq k} \int L(o, \btheta_{\q}(P_{n, S}^{0})) d (G_{n,S}^{1} - \frac{\delta }{1 + \delta} \sqrt{n_1} P)(o) \\
&\leq  \frac{1 + \delta}{\sqrt{n_1}}\left( \frac{8}{n_1^{1/p-1/2}} \log(1 + k) \max_{1 \leq \q \leq k} \left[ \frac{M(\btheta_{\q}(P_{n,S}^{0}))}{n_1^{1-1/p}} + \left( \frac{v(\btheta_{ \q}(P_{n,S}^0) )}{( \frac{\delta}{1 + \delta} )^{2-p} R(\btheta_{\q}(P_{n,S}^{0}))^{2-p}} \right)^{1/p} \right] \right)\\
&\leq  \frac{1 + \delta}{\sqrt{n_1}}\left( \frac{8}{n_1^{1/p-1/2}} \log(1 + k) \sup_{\btheta \in \btheta} \left[ \frac{M(\btheta)}{n_1^{1-1/p}} + \left( \frac{v(\btheta)}{( \frac{\delta}{1 + \delta} )^{2-p} R(\btheta)^{2-p}} \right)^{1/p} \right] \right)\\
&= (1 + \delta) \frac{8}{n_1^{1/p}} \log(1 + k) \sup_{\btheta \in \btheta} \left[ \frac{M(\btheta)}{n_1^{1-1/p}} + \left( \frac{v(\btheta)}{R(\btheta)^{2-p}} \right)^{1/p}\left( \frac{1 + \delta}{\delta}  \right)^{2/p-1} \right]  
\end{align*}
Where for the third inequality we take the $ \sup $ over $ \btheta $. We can also bound the third term with the same expression above. It is now immediate from lemma \ref{finitesampledecomp} that 
\begin{align*}
    E_{S} \int L(o, \btheta_{ \hat{\q} }(P_{n, S}^{0})) d P(o) &\leq (1 + 2 \delta) E_{S} \int L(o, \btheta_{ \tilde{\q} }(P_{n, S}^{0})) d P(o) \\
                                                               &+ 2 \cdot (1 + \delta) \frac{8}{n_1^{1/p}} \log(1 + k) \sup_{\btheta \in \btheta} \left[ \frac{M(\btheta)}{n_1^{1-1/p}} + \left( \frac{v(\btheta)}{R(\btheta)^{2-p}} \right)^{1/p}\left( \frac{1 + \delta}{\delta}  \right)^{2/p-1} \right],
\end{align*}
which was exactly what we set out to prove. 
\end{proof}


\subsection{Example: Binary Regression}
Consider the case where we have i.id. observations $ O_1 = (Y_1 , X_1) , \dots , O_n = (Y_n , X_n) $ such that $ Y_i \in \{0, 1\} $ and $ X \in \mathbb{R}^{d} $ distributed according some $ P \in \mathcal{P} $. We would like to estimate the conditional expectation $ \btheta_0(x) = E(Y \mid X = x) = P(Y = 1 \mid X = x) $.  Let $ \btheta = \{\btheta \mid \btheta : \mathcal{X} \to [0,1] \text{ measurable} \}  $ and choose the quadratic loss function $ L((Y, X), \btheta) = (Y - \btheta(X))^2 $.


We observe that the quadratic loss is bounded by $ 1 $ for all choices of $ \btheta \in \btheta $ and $ O \in \mathcal{O} $. It is stated in \cite[7]{vaart06} that $ M(\btheta) = 1 $ and $ v(\btheta) = \frac{3}{2} \int L(o, \btheta)^2 dP(o)  $ is a valid Bernstein pair for the function $ o \mapsto L(o, \btheta)$. It is also clear that $ R(\btheta) = \int L(o , \btheta) d P(o) \geq 0  $ since the loss function is positive. If we plug these numbers in theorem \ref{finitesample}, then by using $ p = 1 $ and 
\begin{align*}
   ER(\btheta_{\hat{\q}}(P_{n, S}^{0})) &\leq(1 + 2 \delta) ER(\btheta_{ \tilde{\q}}(P_{n,S}^{0})) +(1 + \delta) E \left(  \frac{16}{n_1} \log (1 +k) \sup_{\btheta \in \btheta} \left[ M(\btheta) + \frac{v(\btheta)}{R(\btheta)} \frac{1 + \delta}{\delta}\right]\right)
\end{align*}
In the equation provided, we observe that we can manipulate the following variables: sample size $n$, validation set size $n_1$, parameter $\delta > 0$, and the number of learners $k$. Assuming $k$ remains constant, the validation set size $n_1$ could be either stochastic, depending on the split variable $S$, or fixed as a constant, as illustrated in example \ref{splits}. For instance, we can set $n_1 = n/2$. By establishing a fixed value for $n_1$, we can drop the expectation in the second term. 

The supremum on the left side of the equation might increase significantly because $R(\btheta)$ could be very small. However, by carefully selecting the value of $v(\btheta)$, we can avoid the fraction from growing too large. Note that for any $ \btheta \in \btheta $:
\begin{align*}
    \frac{v(\btheta)}{R(\btheta)} = \frac{3}{2} \frac{\int L(o, \btheta)^2 d P(o)}{\int L(o, \btheta) dP(o)  } \leq \frac{3}{2} \frac{\int L(o, \btheta) \cdot 1 dP(o) }{\int L(o, \btheta) dP(o) } = \frac{3}{2},
\end{align*}
by using $ 0 \leq L(o, \btheta) \leq 1 $ almost surely. Since $ M(\btheta) $ is constant for all $ \btheta \in \btheta $, it is possible to drop the supremum. Combining all the information above we obtain 
\begin{align*}
   ER(\btheta_{\hat{\q}}(P_{n, S}^{0})) &\leq(1 + 2 \delta) ER(\btheta_{ \tilde{\q}}(P_{n,S}^{0})) +(1 + \delta) \frac{16}{n_1} \log (1 +k) \left[ 1 + \frac{3}{2} \frac{1 + \delta}{\delta}\right]\\
                                        &= (1 + 2 \delta) ER(\btheta_{ \tilde{\q}}(P_{n,S}^{0})) +\log (1 +k) \frac{3 + 5\delta}{2\delta}(1 + \delta) \frac{16}{n_1} \\
                                        &= (1 + 2 \delta) ER(\btheta_{ \tilde{\q}}(P_{n,S}^{0})) +\log (1 +k) \frac{3 + 8\delta + 5 \delta^2}{2\delta}\frac{16}{n_1} \\\
                                        &= (1 + 2 \delta) ER(\btheta_{ \tilde{\q}}(P_{n,S}^{0})) +\log (1 +k) \left( \frac{3}{2\delta} + 4 + \frac{5}{2} \delta \right) \frac{16}{n_1},
\end{align*}
We can now adjust for the precision in our bound by choosing $ \delta $ and $ n $. Note that a small delta will mean that the first term $ (1 + 2 \delta) E R(\btheta_{ \tilde{q} }(P_{n, S}^{0})) $ will become smaller, but this is at the expense that the remainder term becomes larger due to the $ \frac{1 + \delta}{ \delta} $ fraction at the end. By choosing $ n $ to be large, we can partially compensate for a smaller delta.

We might, therefore, for each $ n $, choose the $ \delta_n $ that minimizes the left-hand side for the given $ n $. By substituting $ n_1 = n/2 $ into the the left hand side expression and then expanding it we obtain 
\begin{align*}
 ER(\btheta_{ \tilde{\q}}(P_{n,S}^{0})) + 2 \delta ER(\btheta_{ \tilde{\q}}(P_{n,S}^{0})) +\frac{3}{2\delta}\log (1 +k) \frac{32}{n} + 4\log (1 +k) \frac{32}{n} + \frac{5\delta}{2} \log (1 +k)   \frac{32}{n},
\end{align*}
we observe that when $n$ is fixed, two terms remain constant, specifically the first and fourth terms, as they do not depend on $\delta$. The optimal $\delta_n$ can be determined as follows:
\begin{align*}
    \delta_n &= \argmin_{\delta} \frac{1}{\delta} \cdot \frac{3 \cdot 32}{2n} \log(1 + k) + \delta \cdot \left(2ER(\btheta_{ \tilde{\q} }(P_{n, S}^{0})) + \frac{5 \cdot 32}{2n} \log(1 + k) \right) \\
    &= \argmin_{\delta} \frac{1}{\delta} \cdot \frac{48}{n} \log(1 + k) + \delta \cdot \left(2ER(\btheta_{ \tilde{\q} }(P_{n, S}^{0})) + \frac{80}{n} \log(1 + k) \right) \\
    &= \argmin_{\delta} \frac{1}{\delta} a(n) + \delta b(n),
\end{align*}
Essentially, solving for the minimum is a convex optimization problem, with the terms $a(n) = \frac{48}{n} \log(1 + k)$ and $b(n) = 2ER(\btheta_{ \tilde{\q} }(P_{n, S}^{0})) + \frac{80}{n} \log(1 + k)$ remaining constant with respect to $n$. By differentiating the expression above and setting it equal to zero we obtain 
\begin{align*}
    0 &= \left( \frac{1}{\delta} a(n) + \delta b(n) \right)' = - \frac{1}{\delta^2} a(n) + b(n),
\end{align*}
and so we obtain the optimum by isolating $ \delta $ 
\begin{align*}
    \delta_n = \sqrt{\frac{a(n)}{b(n)}},
\end{align*}






%Nonetheless, obtaining a useful bound could be challenging unless $n$ is considerably large. In that case, the oracle risk might be extremely close to the true risk. Unless the remainder constitutes only a minuscule portion of the oracle risk, the finite sample result may not be of significant interest.
%
%To illustrate the problem, consider a concrete example where we might model $ ER(\btheta_{ \tilde{\q} }(P_{n, S}^{0})) $ as a simple function, $ f(n) $, that is monotonically decreasing for $ n \to \infty $. For example
%\begin{align*}
%    f(n)= \frac{1}{2\sqrt{n}} \qquad \text{for }  n \in \mathbb{N} 
%\end{align*}
%which steadily decreases to $ 0 $, but is bounded by $ 0.5 $. 
%
%We now have the choice of solving for $ \delta $ given $ n $, or vice-versa. We might for example be interested in our cross-validation risk to be at most $ 2\% $ more than our oracle risk, which amounts to selecting $ \delta = 0.01 $, we will then solve for $ n $ for an acceptable size on the remainder. For some $ \gamma \in (0, 1) $ which represents the tolerable proportion of our oracle risk that our remainder term can at most attain, and $ \delta = 0.01$, we wish to solve  $ n $ in the following 
%\begin{align*}
%    1.02  \gamma \cdot f(n) \geq \log (1 + k) \frac{154.025 \cdot 16 }{n_1} =  \log (1 + k) \frac{154.025 \cdot 16 }{\frac{n}{2}} = \log (1 + k) \frac{4928.8}{n},
%\end{align*}
%which is equivalent to 
%\begin{align*}
%    \frac{\log (1 + k) \cdot 4928.8}{1.02 \gamma } \leq f(n) \cdot n = \frac{n}{2 \sqrt{n}} = \frac{\sqrt{n}}{ 2} .
%\end{align*}
%For $ k = 5 $ and $ \gamma = 0.01 $, the left hand side is around 865806, multiplying this number by 3 and then squaring it yields us $n = 2998480118544 $, at this point, the oracle risk is $ f(n) \approx 5 \cdot 10^{-26}$. 

%The following result is due to \cite{laan03}: 
%\begin{theorem}[Asymptotic equality]
%    The cross validation selector $ \hat{\q} $ performs asymptotically as well as the oracle selector $ \tilde{\q} $ in the sense that 
%    \begin{align*}
%        \frac{\Delta_{S}( \btheta_{ \hat{\q} } , \btheta_0 )}{ \Delta_{S}( \btheta_{ \tilde{\q} } , \btheta_0) } \to 1 \qquad \text{ in probability for } n \to \infty
%    \end{align*}
%\end{theorem}


\section{The ensemble super learner, eSL}
\section{Simulation results}
\section{Discussion}
Pellentesque tincidunt sodales risus, vulputate iaculis odio dictum vitae. Ut ligula tortor, porta a consequat ac, commodo non risus. Nullam sagittis luctus pretium. Integer vel nibh at justo convallis imperdiet sit amet ut lorem. Sed in gravida turpis. Vestibulum ante ipsum primis in faucibus orci luctus et ultrices posuere cubilia Curae; Sed in massa vitae ligula pellentesque feugiat vitae in risus. Cras iaculis tempus mi, sit amet viverra nulla viverra pellentesque.

\printbibliography

\end{document}
