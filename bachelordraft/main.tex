\documentclass[11pt, a4paper]{article}
\usepackage[margin=3cm]{geometry} 
\usepackage[english, science, hyperref]{ku-frontpage}
\usepackage[utf8]{inputenc}
\usepackage{amsmath,amssymb,amsthm,bm}
\usepackage{mdframed}
\usepackage{mathtools}
\usepackage[
    backend=biber,
    style=alphabetic
]{biblatex}
\bibliography{references.bib}

\setlength\parindent{0pt}
\DeclareMathOperator*{\argmax}{arg\,max} 
\DeclareMathOperator*{\argmin}{arg\,min}

\newtheorem{theorem}{Theorem}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{remark}{Remark}

\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\theoremstyle{remark}
\usepackage{mdframed}

\mdfdefinestyle{examplestyle}{%
    linewidth=1pt,
    innerleftmargin=10pt,
    innerrightmargin=10pt,
    skipabove=10pt, % add vertical space above
    skipbelow=10pt, % add vertical space below
    frametitlefont=\bfseries,
    nobreak=true
}
\newtheorem{example}{Example}
\surroundwithmdframed[style=examplestyle]{example}


\setlength\arraycolsep{2 pt}
\setcounter{tocdepth}{2}
\setcounter{secnumdepth}{2}

\newcommand{\cl}{q}
\newcommand{\btheta}{h}
\newcommand{\empmod}{\mathcal{P}_{\text{emp}}}
\DeclareMathOperator{\expit}{expit}

\assignment{A Bachelor of Science thesis}
\author{Jinyang Liu}


\title{Super Learners}
\subtitle{and their oracle properties}
\date{Submitted: \today}
\advisor{Supervised by Prof. Thomas Gerds\\ Co-supervised by Prof. Niels Richard Hansen \\Department of Mathematical Sciences \\University of Copenhagen, Denmark}
% \frontpageimage{example.png}

\begin{document}
\begingroup
    \fontencoding{T1}\fontfamily{lmr}\selectfont
    \maketitle
    \tableofcontents
    \newpage
\endgroup


\section{Introduction}
In the context of prediction, the goal is to estimate the conditional expectation $ E(Y \mid X = x) $ for i.i.d. observation pairs $ (Y_1 , X_1) , \dots , (Y_n , X_n) $. Depending on the data structure, a variety of standard statistical models can be employed. For instance, if Y is binary, a parametric model like logistic regression might be suitable.
The task of identifying true statistical model $ \mathcal{P} $ for which $ (Y, X) \sim P \in \mathcal{P} $, is challenging, and perhaps infeasible when we only have a limited amount data. It may therefore be motivating ot utilize non-parametric and data-driven regression methods, such as tree-based algorithms like XGBoost or random forests to estimate the conditional mean. However, the underlying assumptions of tree-ensemble methods regarding the data generating process are not explicit, and they may not have probabilistic interpretations. We can nevertheless incorporate these methods as a part of our repertoire, but it is important that we can compare and choose the best method that most effectively accompishes our goal, for example prediction. 

The 'super learner' is the answer to how we can effectively select the 'best' learner (method or algorithm) among the learners that we have in our library of learners. The cross-validation selector, which evaluates learners on their cross-validated (empirical) risk and chooses the one with the lowest risk, is asymptotically equivalent to the oracle selector. The oracle selector finds the learner with the lowest true risk -- the risk obtained by knowing the true distribution. 

The discrete super learner is obtained by applying the cross-validation selector on our data. The asymptotic result shows that the cross-validation selector will select the same learner as the oracle selector when the number of observations goes to $ \infty $. The discrete super learner is not a fixed learner from our library, but rather depends on the available data. It represents the learner chosen by the cross-validation selector, which can vary depending on the amount of data at hand.

We first present the general theory and our goal, which is to estimate the conditional expectation $ E(Y \mid X = x) $ for $ Y, X $ being some outcome-covariate pair. More specifically, we focus on the case where we regress on a binary outcome $ Y \in \{0,1\} $. The conditional expectation of $ Y $ given $ X $ exactly becomes the conditional probability $ P(Y = 1 \mid X = x) $.


\section{Background}

Our setup closely models what is described in \cite{vaart06} and \cite{laan03}. 
Let $ O_1, \ldots, O_n $ be $ n $-i.i.d. observations distributed according to $ P \in \mathcal{P} $ on some measurable space $ (\mathcal{O}, \mathcal{A}) $ where $ O_{i} \in \mathcal{O} $ for each $ i $ and $ \mathcal{P} $ is our statistical model. For a parameter set $ \Theta $ we define the corresponding loss function $ L : \mathcal{O} \times \Theta \to [0, \infty) $ as a measurable map such that our goal is to find an estimator $ \hat{\theta}  $ that minimizes the true risk function $ R: \Theta \to \mathbb{R} $ given as
\begin{align*}
    R(\theta) = \int L(x, \theta)  dP(x) = EL(O_1) 
\end{align*}
The parameter set $ \Theta $ can be Euclidean, but for the focus of this thesis we will consider it as a collection of functions of the form $ \theta : \mathcal{O} \to \mathbb{R} $. 

\begin{example}[Regression functions $ \Theta $] \label{ex:regfunc}
    Let $ O_1 = (Y_1 , X_1) ,\ldots, O_n = (Y_n , X_n) \in  \mathcal{O} = \mathbb{R} \times \mathcal{X} $ be i.i.d. observations distributed according to some $ P \in \mathcal{P} $ such that they satisfy the model 
    \begin{align*}
        Y_1 = \theta_0(X_1) + \varepsilon,
    \end{align*}
    for an unobservable stochastic error term $ \varepsilon $. The goal is to estimate an unknown \textbf{regression function} $ \theta_0 \in \Theta $ where $ \Theta = \{\theta \mid \theta : \mathcal{X} \to \mathbb{R}\}$, is the set of possible regression functions each having $ \mathcal{X} $ as their domain. \cite{vaart06}
\end{example}
\begin{example}[Parameteric family] \label{ex:parametricfam}
    Consider the initial setup from example \ref{ex:regfunc}. If $ Y_i $ is $ \mathcal{B}(\mathbb{R})-\mathcal{B}(\mathbb{R}) $ measurable and $ X_i $ is $ \mathcal{F} - \mathcal{B}(\mathbb{R})  $ measurable for some sigma-algebra $ \mathcal{F} $ on $ \mathcal{X} $, then a \textbf{generalized regression model} could be considered as parametrized family of distributions, $ \mathcal{P} = \{P_{\theta} \mid \theta \in \Theta\} $, given that $ \Theta $ is finite-dimensional.

    We can parametrize the conditional probability distributions for $ Y_1 $ given $ X_1 = x $ as $ \mathcal{Q} = \{Q_{\theta(x)} \mid \theta \in \Theta \} $ such that $ Q_{\theta(x)} $ is a valid probability distribution on $ \mathcal{B}(\mathbb{R}) $ for each $ x \in X $ and $ \theta \in \Theta $. For a given $ P_{\theta} \in \mathcal{P} $ there will exist a $ Q_{\theta} \in \mathcal{Q} $ such that  
    \begin{align*}
        P_{\theta}(Y \in A \mid X = x) = Q_{ \theta(x)}(A) \qquad \text{for all } A \in \mathcal{B}(\mathbb{R}).
    \end{align*}
    If we assume that $ X_1 $ is distributed according to some $ H_0 $ on $ \mathcal{X} $, then the distribution $ P_{\theta} $ over our observations (the joint over $ Y $ and $ X $) will be
    \begin{align*}
        P_{\theta }(X \in A, Y \in B ) = \int_{A} Q_{\theta(x)}(B) d H_{0}(x) 
    \end{align*}
    for every $ A \in \mathcal{F} $ and $ B \in \mathcal{B}(\mathbb{R}) $. 
\end{example}
\begin{example}[Logistic regression model] \label{logregmod}
    Let $ O_1 = (Y_1 , X_n) , \ldots, O_n = (Y_n , X_n) \in \mathcal{O} = \{0,1\} \times \mathcal{X} $ be i.i.d. observations from some distribution $ P_{\theta_0} \in \mathcal{P} $, where $ Y_i $ is binary and $ \mathcal{X} \subseteq \mathbb{R}^{k} $. We would like to estimate the parameter function $ \theta_{0} \in \Theta $
\begin{align*}
    \theta_0(x) = E(Y_1 \mid X_1 = x) = P_{\theta_0}(Y_1 = 1 \mid X_1 = x),
\end{align*}
In logistic regression we assume that $ \Theta = \{x \mapsto \expit(\beta x) \mid \beta \in \mathbb{R}^{k}\} $, so $ \theta_0(x) = \expit(\beta_0 x) $, then the goal becomes to estimate the $ k $-dimensional parameter $ \beta_0 $, in this case the $ \mathbb{R}^{k} $ parameter $ \beta_0  $ completely determines $ \theta_0 $, so $ \Theta $ is also $ k $-dimensional. % I am not sure if the last is true

The conditional distributions of $ Y_1 $ given $ X_1 = x $ are Bernoulli distributions and can be parametrized as $ \mathcal{Q} = \{\operatorname{Ber}(\expit(\beta x )) \mid \beta \in \mathbb{R}^{k}  \}  $. Now from example \ref{ex:parametricfam} we know that the statistical model, $ \mathcal{P} $, can be parametrized through $ \beta $, in particular we have 
\begin{align*}
    P_{\beta}(Y_1= 1 , X_1 \in A) &= \int_{A} Q_{\theta(x)}(\{1\}) dH_{0}(x)\\
 &= \int_{A} \expit(\beta x )  d H_0(x) 
\end{align*}
If $ H_{0} $ has density $ f $ w.r.t. Lebesgue measure, we can write
\begin{align*}
    P_{\beta}(Y_1= 1 , X_1 \in A) &= \int_{A} \expit(\beta x ) f(x)  d m(x) 
\end{align*}
\end{example}
We will now turn our attention to statistical estimators. Statistical literature commonly write that an estimator is stochastic variable taking values in our parameter space $ \hat{\theta} \in \Theta  $. An estimator is achieved by considering i.i.d. observations $ O_1 , \ldots, O_2 \in\mathcal{O} $ distributed according to some measure $ P $ from some statistical model $ \mathcal{P} $. We leave the model unspecified as it can be both parametric or nonparametric. Now let $ h : \mathcal{O}^{n} \to \Theta $ be a measurable map, an estimator created from $ h $ is the random variable $ T = h(O_1 , \ldots, O_n) $. For $ \Theta \subseteq \mathbb{R}^{k} $ the canonical $ \sigma $-algebra on $ \Theta $ is the Borel algebra, but when the parameter set is a set of functions, the $ \sigma $-algebra can only be chosen after careful consideration of constraints on $ \Theta $. 


\section{The discrete super learner, dSL}

In the following section we introduce the terminology ``estimator algorithm'' which corresponds to the measurable map $ h $ from our finite sample observation space to our parameter space. 
\begin{definition}[Estimator algorithm $ \btheta $]
    An estimator algorithm is a measurable map $ \btheta : \mathcal{O}^{n} \to \Theta $ for $ n \in \mathbb{N} $. 
\end{definition}
\begin{definition}[Statistical Estimator $ \hat{\theta} $]
    Let $ O_1, \ldots, O_n \in \mathcal{O} $ be i.i.d. observations distributed according to some $ P \in \mathcal{P} $ for a statistical model $ \mathcal{P} $ on $ \mathcal{O} $. Let $ \btheta : \mathcal{O}^{n} \to \Theta $ be an estimator algorithm. An estimator is the random variable $ \hat{\theta} = \btheta(O_1 ,\ldots , O_n) \in \Theta $. 
\end{definition}
There is a one-to-one correspondence between the tuples of i.i.d. observations $ (O_1 , \ldots, O_n) \in \mathcal{O}^{n} $ and the empirical measures over $ n $ observations on $ (\mathcal{O} , \mathcal{A}) $ defined as  
\begin{align*}
    P_n(A) = \frac{1}{n} \sum_{i = 1}^{n} \delta_{O_i}(A)\qquad \text{ for } A \in \mathcal{A}.
\end{align*}
Note that the empirical measure is a random variable. Thus, we can write $ \btheta(P_n)$ as an alternative representation of the estimator $\btheta(O_1, \ldots, O_n)$, by adjusting the notation without introducing ambiguity. 

\begin{example}[Prediction algorithm] 
    Consider the setup from example \ref{logregmod}, where we have i.i.d. observations $ O_1 = (Y_1 , X_1) ,\ldots, O_n = (Y_n , X_n) $ such that $ Y_i \in \{0,1\} $ and $ \mathcal{X}\in \mathbb{R}^{k} $ and our goal is to estimate the probability $ \theta(x) = P_{\theta}(Y_1 = 1 \mid X_1 = x ) $...
\end{example}
We would now like to consider the scenario where we have a library (set) of learner algorithms, $ \btheta_1 , \ldots, \btheta_n $. From these algorithms, we can define the set of learners $ \{ \hat{\theta} _{\cl} = \btheta_{\cl}(P_n) | 1 \leq \cl \leq p \} $, where our goal is to find $ \hat{\theta}_{ \hat{\cl} }(P_n) $, which denotes the learner that minimizes $ R $ and $ \hat{\cl}  $ may depend on the observations. 

In order to find $ \hat{\cl}  $ we have to proceed via cross validation. In cross validation, we randomly split our data into a training set and a test set. Let the random binary vector $ S = (S_1,\ldots,S_n) \in \{0,1\}^{n} $ be independent of $ X_1,\ldots, X_n $ such that $ S_i = 0 $ indicates that $ X_i $ should be in the training set and $ S_i = 1 $ indicates that $ X_i $ belongs to the test set. We can define the empirical distributions over these two subsets, $ P_{n,S}^0$ and $ P_{n,S}^{1} $ as
\begin{align*}
    P_{n,S}^{0} &= \frac{1}{n_0} \sum_{i: S_i = 0} \delta_{X_i} \\
    P_{n,S}^{1} &= \frac{1}{1-n_0} \sum_{i: S_i = 1} \delta_{X_i} 
\end{align*}
Where $ n_0 $ would be the number of $ S_i $'s that are marked $ 0 $. 

\begin{example}[Random splits] \label{splits}
    For $ n = 9 $ observations one could for example define the distribution of the random vector $ S $ as 
   \begin{align*}
       P(S = (0, 0, 0, 0, 0, 0, 1, 1, 1)) &= \frac{1}{3} \\
       P(S = (0, 0, 0, 1, 1, 1, 0, 0, 0)) &= \frac{1}{3} \\
       P(S = (1, 1, 1, 0, 0, 0, 0, 0, 0)) &= \frac{1}{3},
   \end{align*}
    i.e. 3-fold cross-validation.

    In general for $ n $ observations we have $ 2^{n} $ ways of choosing which observations should be in the training set and in the validation set. It might not be desirable to define the discrete probabilities for $ S $ over $ \{0,1\}^{n} $ simply as $ \frac{1}{2^{n}} $ for each possible combination of training/validation data, since that would also include the combination where $ n_1 = 0 $. To ensure that we always have $ n_1 > 0 $, then let $ n_1 $ be given, then we see that there are $ \begin{pmatrix}
        n \\ n_1
    \end{pmatrix}$ ways of choosing both the validation and training set. We can therefore define the distribution of $ S $ as 
    \begin{align*}
        P \left(S = s \right) = \begin{pmatrix}
            n \\ n_1
    \end{pmatrix}^{-1} \qquad \text{for each } s \in \{0,1\}^{n} \text{ where } \sum_{i} s_i = n_1
    \end{align*}

\end{example}

\subsection{Risks and selectors}

\begin{definition}[True risk of $ \cl $'th learner averaged over splits]
    Given the data $ O_1, \ldots, O_n \in \mathcal{O} $ and a set of learners $ \{ \theta_{\cl}(P_{n, S}^{0}) \mid 1 \leq \cl \leq k \}, k \in \mathbb{N} $ applied to our training data $ P_{n, S}^{0} $. The risks of these learners averaged over some split-variable $ S $ is given as a function of $ \cl $ 
    \begin{align*}
        \cl \mapsto E_S \int L(o, \theta_{\cl}(P_{n,S}^{0}) ) dP(o) = E_S R( \theta_\cl(P_{n,S}^{0})) 
    \end{align*}
    Where $ P $ is the true distribution for our data $ X $.
\end{definition}

\begin{definition}[Oracle selector]
    The oracle selector is a function $ \tilde{\cl}: \mathcal{O}^{n} \to \{1,\ldots,k\} $  which finds the learner that minimizes the true risk given our data $ O_1 , \ldots , O_n \in O$. 
    \begin{align*}
        \tilde{\cl}(O_1 , \ldots, O_n) = \argmin_{1 \leq \cl \leq k} E_S R( \theta _\cl (P_{n,S}^0 )) 
    \end{align*}
    Where $ P_{n ,s}^{0} $ is the empirical distribution over the training set of $O_1 , \ldots, O_n $ as specified by some split-variable $ S $. 
\end{definition}
In similar manner to the above the defintions, we can define the cross-validation risk and the cross-validation selector for our learners 

\begin{definition}[Cross-validation risk of $ \cl $'th learner averaged over splits]
    Given the data $ O_1, \ldots, O_n \in \mathcal{O} $ and a set of learners $ \{ \theta_{\cl}(P_{n, S}^{n}) \mid 1 \leq \cl \leq k \}, k \in \mathbb{N} $. The cross-validation risks of these learners averaged over some split-variable $ S $ is given as a function of $ \cl $ 
    \begin{align*}
        \cl \mapsto E_S \int L(o, \theta_{\cl}(P_{n,S}^{0}) ) dP_{n, S}^{1}(o) = E_S \hat{R}( \theta_\cl(P_{n,S}^{0})) 
    \end{align*}
    Where $ P_{n,S}^{1} $ is the empircal distribution over the validation of $ O_1 , \dots, O_n $. We write $ \hat{R} $ for the empirical risk over the validation set. 
\end{definition}

\begin{definition}[Cross-validation selector]
    The cross-validation selector is a function $ \hat{\cl}: \mathcal{O}^{n} \to \{1,\ldots,k\} $  which finds the learner that minimizes the cross-validation risk given our data $ O_1 , \dots , O_n \in \mathcal{O} $. 
    \begin{align*}
        \hat{\cl}(O_1 , \dots , O_n) = \argmin_{1 \leq \cl \leq k} E_S \hat{R} ( \theta _\cl (P_{n,S}^0 )) 
    \end{align*}
    Where $ \hat{R}  $ is the empirical risk over the validation set and $ P_{n ,s}^{0} $ is the empirical distribution over the training set of $ O_1 , \dots , O_n  $ as specified by some split-variable $ S $. 
\end{definition}
We are interested in the risk difference between the cross-validation selector and and the oracle selector, we remark that the optimal risk is attained at the true value $ \theta_0 $ 
\begin{align*}
    R(\theta_0) = \int L(o, \theta_0)  dP(o),
\end{align*}
and clearly it is the case that $ R(\theta_0) \leq R( \theta  ) $ for any learner $ \theta $ of $ \theta_0 $.
Given a set of learners we define the centered conditional risk as the difference 
\begin{align*}
    \Delta_{S}( \theta_{ \hat{\cl} }, \theta_0 ) &= R( \theta _{ \hat{\cl} }(P_{n, S}^{0})) -R(\theta_0) \\
                                                       &= E_{S} \int L(o, \theta_{ \hat{\cl} }(P_{n, S}^{0})) - L(o, \theta_0) dP(o) 
\end{align*}

\subsection{Oracle inequalities}
We introduce the notation $Pf$ for the integral $\int f dP$ of an integrable function $f$ with respect to $P$. Additionally, if $P_n$ represents the empirical measure of $O_1, \dots, O_n$, we denote the empirical process indexed over an appropriate class of functions $\mathcal{F}$ as $G_n f = \sqrt{n}(P_n f - P f)$. Furthermore, we extend this notation to $G_{n, S}^{i} f = \sqrt{n}(P_{n, S}^{i} - Pf)$ for the empirical processes that correspond to applying the empirical measure over either the training sample or validation sample.

\begin{lemma}[Lemma 2.1 in \cite{vaart06}]
   For $ \delta > 0 $ it holds that
   \begin{align*}
       E_{S} \int L(o, \theta_{ \hat{\cl}}(P_{n, S}^{0})) dP(o) &\leq (1 + 2 \delta) E_{S} \int L(o, \theta_{ \tilde{\cl} }(P_{n, S}^{0})) d P(o) \\ 
                                                                &+\frac{1}{\sqrt{n_1} } E_{S} \max_{1 \leq \cl \leq k} \int L(o, \theta_{\cl}(P_{n, S}^{0})) d ((1 + \delta) G_{n,S}^{1} - \delta \sqrt{n_1} P)(o)  \\
                                                                &-\frac{1}{\sqrt{n_1} } E_{S} \max_{1 \leq \cl \leq k} \int L(o, \theta_{\cl}(P_{n, S}^{0})) d ((1 + \delta) G_{n,S}^{1} + \delta \sqrt{n_1} P)(o)  \\
   \end{align*}
\end{lemma}
\begin{proof}
    See appendix
\end{proof}
\begin{theorem}[Finite Sample Result: Theorem 2.3 in \cite{vaart06}] \label{finitesample}
   For $ \theta \in \Theta $ let $ (M(\theta) , v(\theta)) $ be a Bernstein pair for the function $ o \mapsto L(o, \theta) $ and assume that $ R(\theta) = \int L(o, \theta) d P(o) \geq 0 $ for every $ \theta \in \Theta $. Then for $ \delta > 0 $ and $ 1 \leq p \leq 2 $ it holds that 
   \begin{align*}
       ER(\theta_{\hat{\cl}}(P_{n, S}^{0})) \leq&(1 + 2 \delta) ER(\theta_{ \tilde{\cl}}(P_{n,S}^{0})) +\\
                                              &(1 + \delta) E \left(  \frac{16}{n_1^{1/p}} \log (1 +k) \sup_{\theta \in \Theta} \left[ \frac{M(\theta)}{n_1^{1-1/p}} +  \left( \frac{v(\theta)}{R(\theta)^{2-p}} \right)^{1/p} \left( \frac{1 + \delta}{\delta} \right)^{2/p-1} \right]\right),
   \end{align*}
   where $ k $ is the number of learners in our library $ \{\theta_{\cl}(P_{n, S}^{0}) \mid 1 \leq \cl \leq k\} $. 
\end{theorem}

\subsection{Example: Binary Regression}
Consider the case where we have i.id. observations $ O_1 = (Y_1 , X_1) , \dots , O_n = (Y_n , X_n) $ such that $ Y_i \in \{0, 1\} $ and $ X \in \mathbb{R}^{d} $ distributed according some $ P \in \mathcal{P} $. We would like to estimate the conditional expectation $ \theta_0(x) = E(Y \mid X = x) = P(Y = 1 \mid X = x) $.  Let $ \Theta = \{\theta \mid \theta : \mathcal{X} \to [0,1] \text{ measurable} \}  $ and choose the quadratic loss function $ L((Y, X), \theta) = (Y - \theta(X))^2 $.


We observe that the quadratic loss is bounded by $ 1 $ for all choices of $ \theta \in \Theta $ and $ O \in \mathcal{O} $. It is stated in \cite[7]{vaart06} that $ M(\theta) = 1 $ and $ v(\theta) = \frac{3}{2} \int L(o, \theta)^2 dP(o)  $ is a valid Bernstein pair for the function $ o \mapsto L(o, \theta)$. It is also clear that $ R(\theta) = \int L(o , \theta) d P(o) \geq 0  $ since the loss function is positive. If we plug these numbers in theorem \ref{finitesample}, then by using $ p = 1 $ and 
\begin{align*}
   ER(\theta_{\hat{\cl}}(P_{n, S}^{0})) &\leq(1 + 2 \delta) ER(\theta_{ \tilde{\cl}}(P_{n,S}^{0})) +(1 + \delta) E \left(  \frac{16}{n_1} \log (1 +k) \sup_{\theta \in \Theta} \left[ M(\theta) + \frac{v(\theta)}{R(\theta)} \frac{1 + \delta}{\delta}\right]\right)
\end{align*}
In the equation provided, we observe that we can manipulate the following variables: sample size $n$, validation set size $n_1$, parameter $\delta > 0$, and the number of learners $k$. Assuming $k$ remains constant, the validation set size $n_1$ could be either stochastic, depending on the split variable $S$, or fixed as a constant, as illustrated in example \ref{splits}. For instance, we can set $n_1 = n/2$. By establishing a fixed value for $n_1$, we can drop the expectation in the second term. 

The supremum on the left side of the equation might increase significantly because $R(\theta)$ could be very small. However, by carefully selecting the value of $v(\theta)$, we can avoid the fraction from growing too large. Note that for any $ \theta \in \Theta $:
\begin{align*}
    \frac{v(\theta)}{R(\theta)} = \frac{3}{2} \frac{\int L(o, \theta)^2 d P(o)}{\int L(o, \theta) dP(o)  } \leq \frac{3}{2} \frac{\int L(o, \theta) \cdot 1 dP(o) }{\int L(o, \theta) dP(o) } = \frac{3}{2},
\end{align*}
by using $ 0 \leq L(o, \theta) \leq 1 $ almost surely. Since $ M(\theta) $ is constant for all $ \theta \in \Theta $, it is possible to drop the supremum. Combining all the information above we obtain 
\begin{align*}
   ER(\theta_{\hat{\cl}}(P_{n, S}^{0})) &\leq(1 + 2 \delta) ER(\theta_{ \tilde{\cl}}(P_{n,S}^{0})) +(1 + \delta) \frac{16}{n_1} \log (1 +k) \left[ 1 + \frac{3}{2} \frac{1 + \delta}{\delta}\right]\\
                                        &= (1 + 2 \delta) ER(\theta_{ \tilde{\cl}}(P_{n,S}^{0})) +\log (1 +k) \frac{3 + 5\delta}{2\delta}(1 + \delta) \frac{16}{n_1} \\
                                        &= (1 + 2 \delta) ER(\theta_{ \tilde{\cl}}(P_{n,S}^{0})) +\log (1 +k) \frac{3 + 8\delta + 5 \delta^2}{2\delta}\frac{16}{n_1} \\\
                                        &= (1 + 2 \delta) ER(\theta_{ \tilde{\cl}}(P_{n,S}^{0})) +\log (1 +k) \left( \frac{3}{2\delta} + 4 + \frac{5}{2} \delta \right) \frac{16}{n_1},
\end{align*}
We can now adjust for the precision in our bound by choosing $ \delta $ and $ n $. Note that a small delta will mean that the first term $ (1 + 2 \delta) E R(\theta_{ \tilde{q} }(P_{n, S}^{0})) $ will become smaller, but this is at the expense that the remainder term becomes larger due to the $ \frac{1 + \delta}{ \delta} $ fraction at the end. By choosing $ n $ to be large, we can partially compensate for a smaller delta.

Nonetheless, obtaining a useful bound could be challenging unless $n$ is considerably large. In that case, the oracle risk might be extremely close to the true risk. Unless the remainder constitutes only a minuscule portion of the oracle risk, the finite sample result may not be of significant interest.

To illustrate the problem, consider a concrete example where we might model $ ER(\theta_{ \tilde{\cl} }(P_{n, S}^{0})) $ as a simple function, $ f(n) $, that is monotonically decreasing for $ n \to \infty $. For example
\begin{align*}
    f(n)= \frac{1}{2\sqrt{n}} \qquad \text{for }  n \in \mathbb{N} 
\end{align*}
which steadily decreases to $ 0 $, but is bounded by $ 0.5 $. 

We now have the choice of solving for $ \delta $ given $ n $, or vice-versa. We might for example be interested in our cross-validation risk to be at most $ 2\% $ more than our oracle risk, which amounts to selecting $ \delta = 0.01 $, we will then solve for $ n $ for an acceptable size on the remainder. For some $ \gamma \in (0, 1) $ which represents the tolerable proportion of our oracle risk that our remainder term can at most attain, and $ \delta = 0.01$, we wish to solve  $ n $ in the following 
\begin{align*}
    1.02  \gamma \cdot f(n) \geq \log (1 + k) \frac{154.025 \cdot 16 }{n_1} =  \log (1 + k) \frac{154.025 \cdot 16 }{\frac{n}{2}} = \log (1 + k) \frac{4928.8}{n},
\end{align*}
which is equivalent to 
\begin{align*}
    \frac{\log (1 + k) \cdot 4928.8}{1.02 \gamma } \leq f(n) \cdot n = \frac{n}{2 \sqrt{n}} = \frac{\sqrt{n}}{ 2} .
\end{align*}
For $ k = 5 $ and $ \gamma = 0.01 $, the left hand side is around 865806, multiplying this number by 3 and then squaring it yields us $n = 2998480118544 $. 

%The following result is due to \cite{laan03}: 
%\begin{theorem}[Asymptotic equality]
%    The cross validation selector $ \hat{\cl} $ performs asymptotically as well as the oracle selector $ \tilde{\cl} $ in the sense that 
%    \begin{align*}
%        \frac{\Delta_{S}( \theta_{ \hat{\cl} } , \theta_0 )}{ \Delta_{S}( \theta_{ \tilde{\cl} } , \theta_0) } \to 1 \qquad \text{ in probability for } n \to \infty
%    \end{align*}
%\end{theorem}


\section{The ensemble super learner, eSL}
\section{Simulation results}
\section{Discussion}
Pellentesque tincidunt sodales risus, vulputate iaculis odio dictum vitae. Ut ligula tortor, porta a consequat ac, commodo non risus. Nullam sagittis luctus pretium. Integer vel nibh at justo convallis imperdiet sit amet ut lorem. Sed in gravida turpis. Vestibulum ante ipsum primis in faucibus orci luctus et ultrices posuere cubilia Curae; Sed in massa vitae ligula pellentesque feugiat vitae in risus. Cras iaculis tempus mi, sit amet viverra nulla viverra pellentesque.



\end{document}
