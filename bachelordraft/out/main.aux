\relax 
\providecommand\zref@newlabel[2]{}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\abx@aux@refcontext{ynt/global//global/global}
\providecommand \oddpage@label [2]{}
\abx@aux@cite{0}{lauritzen2023fundamentals}
\abx@aux@segm{0}{0}{lauritzen2023fundamentals}
\abx@aux@cite{0}{laan03}
\abx@aux@segm{0}{0}{laan03}
\abx@aux@cite{0}{van2007super}
\abx@aux@segm{0}{0}{van2007super}
\abx@aux@cite{0}{van2007super}
\abx@aux@segm{0}{0}{van2007super}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{3}{section.1}\protected@file@percent }
\abx@aux@cite{0}{vaart06}
\abx@aux@segm{0}{0}{vaart06}
\abx@aux@cite{0}{laan03}
\abx@aux@segm{0}{0}{laan03}
\abx@aux@cite{0}{vaart06}
\abx@aux@segm{0}{0}{vaart06}
\abx@aux@cite{0}{laan03}
\abx@aux@segm{0}{0}{laan03}
\@writefile{toc}{\contentsline {section}{\numberline {2}Background}{4}{section.2}\protected@file@percent }
\newlabel{l2risk}{{1}{4}{Background}{equation.2.1}{}}
\newlabel{minrisk}{{2}{4}{}{theorem.2}{}}
\abx@aux@cite{0}{gyorfi2002distribution}
\abx@aux@segm{0}{0}{gyorfi2002distribution}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Learning algorithms and learners}{5}{subsection.2.1}\protected@file@percent }
\abx@aux@cite{0}{chen2016xgboost}
\abx@aux@segm{0}{0}{chen2016xgboost}
\abx@aux@cite{0}{chen2016xgboost}
\abx@aux@segm{0}{0}{chen2016xgboost}
\@writefile{toc}{\contentsline {section}{\numberline {3}The Discrete Super Learner}{6}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Library of learners}{6}{subsection.3.1}\protected@file@percent }
\abx@aux@cite{0}{laan03}
\abx@aux@segm{0}{0}{laan03}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Cross-validation methodology}{7}{subsection.3.2}\protected@file@percent }
\newlabel{splits}{{2}{7}{Random splits}{example.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}K-fold cross validation}{7}{subsection.3.3}\protected@file@percent }
\abx@aux@cite{0}{laan03}
\abx@aux@segm{0}{0}{laan03}
\abx@aux@cite{0}{vaart06}
\abx@aux@segm{0}{0}{vaart06}
\abx@aux@cite{0}{laan03}
\abx@aux@segm{0}{0}{laan03}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Risks and selectors}{8}{subsection.3.4}\protected@file@percent }
\abx@aux@cite{0}{laan03}
\abx@aux@segm{0}{0}{laan03}
\abx@aux@cite{0}{vaart06}
\abx@aux@segm{0}{0}{vaart06}
\abx@aux@cite{0}{vaart06}
\abx@aux@segm{0}{0}{vaart06}
\newlabel{def:cvselector}{{8}{9}{Cross-validation selector \parencite {laan03}}{theorem.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Oracle property}{9}{subsection.3.5}\protected@file@percent }
\newlabel{finitesampledecomp}{{10}{9}{Lemma 2.1 in \parencite {vaart06}}{theorem.10}{}}
\abx@aux@cite{0}{vaart06}
\abx@aux@segm{0}{0}{vaart06}
\abx@aux@cite{0}{vaart06}
\abx@aux@segm{0}{0}{vaart06}
\abx@aux@cite{0}{vaart06}
\abx@aux@segm{0}{0}{vaart06}
\newlabel{bernstein}{{2}{10}{Bernstein pair \parencite {vaart06}}{equation.3.2}{}}
\newlabel{unifbernstein}{{12}{10}{}{theorem.12}{}}
\newlabel{ex:bernsteinexample}{{3}{10}{Binary regression}{example.3}{}}
\newlabel{finitesamplebound}{{13}{10}{Lemma 2.2 in \parencite {vaart06}}{theorem.13}{}}
\newlabel{finitesample}{{14}{10}{Theorem 2.3 in \parencite {vaart06}}{theorem.14}{}}
\abx@aux@cite{0}{van2007super}
\abx@aux@segm{0}{0}{van2007super}
\newlabel{cor:dslasymptoticequivalence}{{15}{12}{Asymptotic equivalence}{theorem.15}{}}
\abx@aux@cite{0}{breiman1996stacked}
\abx@aux@segm{0}{0}{breiman1996stacked}
\@writefile{toc}{\contentsline {section}{\numberline {4}The Ensemble Super Learner}{13}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Level 1 data}{13}{subsection.4.1}\protected@file@percent }
\abx@aux@cite{0}{breiman1996stacked}
\abx@aux@segm{0}{0}{breiman1996stacked}
\abx@aux@cite{0}{van2007super}
\abx@aux@segm{0}{0}{van2007super}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Meta learners}{14}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Ensemble super learner}{14}{subsection.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Oracle property}{14}{subsection.4.4}\protected@file@percent }
\newlabel{eq:meta_learning_algorithm}{{3}{14}{Oracle property}{equation.4.3}{}}
\newlabel{eq:meta_learning_algorithm_cv}{{4}{15}{Oracle property}{equation.4.4}{}}
\abx@aux@cite{0}{van2007super}
\abx@aux@segm{0}{0}{van2007super}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Choice of meta learning algorithm}{16}{subsection.4.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{Constrained regression and the $ k$-simplex}{16}{section*.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The parameter set $ \mathcal  {A} $ as a $ k$-simplex for $ k= 3 $. Here $ \mathcal  {A}_n $ is visualized as points on the surface.\relax }}{17}{figure.caption.3}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:simplex}{{1}{17}{The parameter set $ \mathcal {A} $ as a $ \ml $-simplex for $ \ml = 3 $. Here $ \mathcal {A}_n $ is visualized as points on the surface.\relax }{figure.caption.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Simulation results}{17}{section.5}\protected@file@percent }
\newlabel{sec:simulations}{{5}{17}{Simulation results}{section.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The data-generating regression plotted as a heat map\relax }}{18}{figure.caption.4}\protected@file@percent }
\newlabel{fig:trueplot}{{2}{18}{The data-generating regression plotted as a heat map\relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces The predictions of the main effects logistic regression and XGBoost fitted on 1000 observations\relax }}{19}{figure.caption.5}\protected@file@percent }
\newlabel{fig:predictpar}{{3}{19}{The predictions of the main effects logistic regression and XGBoost fitted on 1000 observations\relax }{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces XGBoost becoming better at approximating the true regression as the sample size increases\relax }}{20}{figure.caption.6}\protected@file@percent }
\newlabel{fig:xgboost10k}{{4}{20}{XGBoost becoming better at approximating the true regression as the sample size increases\relax }{figure.caption.6}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Discrete super learner\relax }}{20}{algorithm.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}The discrete super learner}{21}{subsection.5.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces The risk of the discrete super learner compared to other learners. $ N = 3500 $\relax }}{21}{figure.caption.7}\protected@file@percent }
\newlabel{fig:loss_min_of_both}{{5}{21}{The risk of the discrete super learner compared to other learners. $ N = 3500 $\relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces The risk of the discrete super learner compared to other learners. $ N = 3500 $\relax }}{21}{figure.caption.8}\protected@file@percent }
\newlabel{fig:loss_jumps}{{6}{21}{The risk of the discrete super learner compared to other learners. $ N = 3500 $\relax }{figure.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Variances of learner predictions for a single observation, each trained on $n $ samples and evaluated $ K = 1000 $ times on a single observation\relax }}{22}{figure.caption.9}\protected@file@percent }
\newlabel{fig:pred_probs_boxplot}{{7}{22}{Variances of learner predictions for a single observation, each trained on $n $ samples and evaluated $ K = 1000 $ times on a single observation\relax }{figure.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Predictions for a single observation by the three learners fitted on $ n = 1000 $\relax }}{22}{figure.caption.10}\protected@file@percent }
\newlabel{fig:dsl_preds_n1k}{{8}{22}{Predictions for a single observation by the three learners fitted on $ n = 1000 $\relax }{figure.caption.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Discussion}{22}{subsection.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}The ensemble super learner}{23}{subsection.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Discussion}{23}{subsection.5.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Appendix}{23}{section.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Proof of lemma \ref {finitesampledecomp}}{23}{subsection.6.1}\protected@file@percent }
\newlabel{eq:minizing}{{5}{23}{Proof of lemma \ref {finitesampledecomp}}{equation.6.5}{}}
\abx@aux@read@bbl@mdfivesum{25BA502C9B83856C92126FB9A0DE21BA}
\abx@aux@defaultrefcontext{0}{breiman1996stacked}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{gyorfi2002distribution}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{laan03}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{vaart06}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{van2007super}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{chen2016xgboost}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{lauritzen2023fundamentals}{ynt/global//global/global}
\gdef \@abspage@last{25}
