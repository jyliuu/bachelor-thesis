\relax 
\providecommand\zref@newlabel[2]{}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\abx@aux@refcontext{ynt/global//global/global}
\abx@aux@cite{0}{lauritzen2023fundamentals}
\abx@aux@segm{0}{0}{lauritzen2023fundamentals}
\abx@aux@cite{0}{laan03}
\abx@aux@segm{0}{0}{laan03}
\abx@aux@cite{0}{van2007super}
\abx@aux@segm{0}{0}{van2007super}
\abx@aux@cite{0}{van2007super}
\abx@aux@segm{0}{0}{van2007super}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{3}{section.1}\protected@file@percent }
\abx@aux@cite{0}{vaart06}
\abx@aux@segm{0}{0}{vaart06}
\abx@aux@cite{0}{laan03}
\abx@aux@segm{0}{0}{laan03}
\abx@aux@cite{0}{vaart06}
\abx@aux@segm{0}{0}{vaart06}
\abx@aux@cite{0}{laan03}
\abx@aux@segm{0}{0}{laan03}
\@writefile{toc}{\contentsline {section}{\numberline {2}Background}{4}{section.2}\protected@file@percent }
\newlabel{l2risk}{{1}{4}{Background}{equation.2.1}{}}
\newlabel{minrisk}{{2}{4}{}{theorem.2}{}}
\abx@aux@cite{0}{gyorfi2002distribution}
\abx@aux@segm{0}{0}{gyorfi2002distribution}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Learning algorithms and learners}{5}{subsection.2.1}\protected@file@percent }
\abx@aux@cite{0}{chen2016xgboost}
\abx@aux@segm{0}{0}{chen2016xgboost}
\abx@aux@cite{0}{chen2016xgboost}
\abx@aux@segm{0}{0}{chen2016xgboost}
\@writefile{toc}{\contentsline {section}{\numberline {3}The Discrete Super Learner}{6}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Library of learners}{6}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Cross-validation methodology}{7}{subsection.3.2}\protected@file@percent }
\newlabel{splits}{{2}{7}{Random splits}{example.2}{}}
\abx@aux@cite{0}{laan03}
\abx@aux@segm{0}{0}{laan03}
\abx@aux@cite{0}{vaart06}
\abx@aux@segm{0}{0}{vaart06}
\abx@aux@cite{0}{laan03}
\abx@aux@segm{0}{0}{laan03}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Risks and selectors}{8}{subsection.3.3}\protected@file@percent }
\abx@aux@cite{0}{laan03}
\abx@aux@segm{0}{0}{laan03}
\abx@aux@cite{0}{vaart06}
\abx@aux@segm{0}{0}{vaart06}
\abx@aux@cite{0}{vaart06}
\abx@aux@segm{0}{0}{vaart06}
\newlabel{def:cvselector}{{9}{9}{Cross-validation selector \parencite {laan03}}{theorem.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Oracle inequalities}{9}{subsection.3.4}\protected@file@percent }
\newlabel{finitesampledecomp}{{11}{9}{Lemma 2.1 in \parencite {vaart06}}{theorem.11}{}}
\abx@aux@cite{0}{vaart06}
\abx@aux@segm{0}{0}{vaart06}
\abx@aux@cite{0}{vaart06}
\abx@aux@segm{0}{0}{vaart06}
\abx@aux@cite{0}{vaart06}
\abx@aux@segm{0}{0}{vaart06}
\newlabel{bernstein}{{2}{10}{Bernstein pair \parencite {vaart06}}{equation.3.2}{}}
\newlabel{unifbernstein}{{13}{10}{}{theorem.13}{}}
\newlabel{ex:bernsteinexample}{{4}{10}{Binary regression}{example.4}{}}
\newlabel{finitesamplebound}{{14}{10}{Lemma 2.2 in \parencite {vaart06}}{theorem.14}{}}
\newlabel{finitesample}{{15}{10}{Theorem 2.3 in \parencite {vaart06}}{theorem.15}{}}
\newlabel{cor:dslasymptoticequivalence}{{16}{12}{Asymptotic equivalence}{theorem.16}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}The Ensemble Super Learner}{13}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}K-fold cross validation}{13}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Level 1 data}{13}{subsection.4.2}\protected@file@percent }
\abx@aux@cite{0}{van2007super}
\abx@aux@segm{0}{0}{van2007super}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Meta learners}{14}{subsection.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Ensemble super learner}{14}{subsection.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Oracle inequalities}{14}{subsection.4.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}Simulation results}{16}{section.5}\protected@file@percent }
\newlabel{sec:simulations}{{5}{16}{Simulation results}{section.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The data-generating regression plotted as a heat map\relax }}{16}{figure.caption.2}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:trueplot}{{1}{16}{The data-generating regression plotted as a heat map\relax }{figure.caption.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The predictions of the main effects logistic regression and XGBoost fitted on 1000 observations\relax }}{17}{figure.caption.3}\protected@file@percent }
\newlabel{fig:predictpar}{{2}{17}{The predictions of the main effects logistic regression and XGBoost fitted on 1000 observations\relax }{figure.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces XGBoost becoming better at approximating the true regression as the sample size increases\relax }}{18}{figure.caption.4}\protected@file@percent }
\newlabel{fig:xgboost10k}{{3}{18}{XGBoost becoming better at approximating the true regression as the sample size increases\relax }{figure.caption.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Simulation results for the discrete super learner}{19}{subsection.5.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces The risk of the discrete super learner compared to other learners. $ N = 3500 $\relax }}{19}{figure.caption.5}\protected@file@percent }
\newlabel{fig:loss_min_of_both}{{4}{19}{The risk of the discrete super learner compared to other learners. $ N = 3500 $\relax }{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces The risk of the discrete super learner compared to other learners. $ N = 3500 $\relax }}{19}{figure.caption.6}\protected@file@percent }
\newlabel{fig:loss_jumps}{{5}{19}{The risk of the discrete super learner compared to other learners. $ N = 3500 $\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Variances of learner predictions for a single observation, each trained on $n $ samples and evaluated $ K = 1000 $ times on a single observation\relax }}{20}{figure.caption.7}\protected@file@percent }
\newlabel{fig:pred_probs_boxplot}{{6}{20}{Variances of learner predictions for a single observation, each trained on $n $ samples and evaluated $ K = 1000 $ times on a single observation\relax }{figure.caption.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Discussion of results}{20}{subsection.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6}Appendix}{21}{section.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Proof of lemma \ref {finitesampledecomp}}{21}{subsection.6.1}\protected@file@percent }
\newlabel{eq:minizing}{{3}{21}{Proof of lemma \ref {finitesampledecomp}}{equation.6.3}{}}
\abx@aux@read@bbl@mdfivesum{C8F6BF36E6723C6E5C0A7B87392B79AD}
\abx@aux@defaultrefcontext{0}{gyorfi2002distribution}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{laan03}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{vaart06}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{van2007super}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{chen2016xgboost}{ynt/global//global/global}
\abx@aux@defaultrefcontext{0}{lauritzen2023fundamentals}{ynt/global//global/global}
\gdef \@abspage@last{22}
